{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":11859,"status":"ok","timestamp":1764315343495,"user":{"displayName":"Christian Candido","userId":"04121477428710958590"},"user_tz":-480},"id":"HgnKENK_2VaD","outputId":"567885c9-0ee8-4c5e-9d3f-656d160419bd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: rasterio in /usr/local/lib/python3.12/dist-packages (1.4.3)\n","Collecting pytorch_tabular\n","  Downloading pytorch_tabular-1.1.1-py2.py3-none-any.whl.metadata (24 kB)\n","Requirement already satisfied: affine in /usr/local/lib/python3.12/dist-packages (from rasterio) (2.4.0)\n","Requirement already satisfied: attrs in /usr/local/lib/python3.12/dist-packages (from rasterio) (25.4.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from rasterio) (2025.11.12)\n","Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.12/dist-packages (from rasterio) (8.3.1)\n","Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.12/dist-packages (from rasterio) (0.7.2)\n","Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.12/dist-packages (from rasterio) (2.0.2)\n","Requirement already satisfied: click-plugins in /usr/local/lib/python3.12/dist-packages (from rasterio) (1.1.1.2)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from rasterio) (3.2.5)\n","Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from pytorch_tabular) (2.9.0+cu126)\n","Collecting numpy>=1.24 (from rasterio)\n","  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.12/dist-packages (from pytorch_tabular) (2.2.2)\n","Requirement already satisfied: scikit-learn>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from pytorch_tabular) (1.6.1)\n","Collecting pytorch-lightning<2.5.0,>=2.0.0 (from pytorch_tabular)\n","  Downloading pytorch_lightning-2.4.0-py3-none-any.whl.metadata (21 kB)\n","Requirement already satisfied: omegaconf>=2.3.0 in /usr/local/lib/python3.12/dist-packages (from pytorch_tabular) (2.3.0)\n","Collecting torchmetrics<1.6.0,>=0.10.0 (from pytorch_tabular)\n","  Downloading torchmetrics-1.5.2-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: tensorboard!=2.5.0,>2.2.0 in /usr/local/lib/python3.12/dist-packages (from pytorch_tabular) (2.19.0)\n","Collecting protobuf<5.29.0,>=3.20.0 (from pytorch_tabular)\n","  Downloading protobuf-5.28.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n","Collecting pytorch-tabnet==4.1 (from pytorch_tabular)\n","  Downloading pytorch_tabnet-4.1.0-py3-none-any.whl.metadata (15 kB)\n","Requirement already satisfied: PyYAML<6.1.0,>=5.4 in /usr/local/lib/python3.12/dist-packages (from pytorch_tabular) (6.0.3)\n","Requirement already satisfied: matplotlib>3.1 in /usr/local/lib/python3.12/dist-packages (from pytorch_tabular) (3.10.0)\n","Requirement already satisfied: ipywidgets in /usr/local/lib/python3.12/dist-packages (from pytorch_tabular) (7.7.1)\n","Collecting einops<0.8.0,>=0.6.0 (from pytorch_tabular)\n","  Downloading einops-0.7.0-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: rich>=11.0.0 in /usr/local/lib/python3.12/dist-packages (from pytorch_tabular) (13.9.4)\n","Requirement already satisfied: scipy>1.4 in /usr/local/lib/python3.12/dist-packages (from pytorch-tabnet==4.1->pytorch_tabular) (1.16.3)\n","Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.12/dist-packages (from pytorch-tabnet==4.1->pytorch_tabular) (4.67.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>3.1->pytorch_tabular) (1.3.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>3.1->pytorch_tabular) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>3.1->pytorch_tabular) (4.60.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>3.1->pytorch_tabular) (1.4.9)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>3.1->pytorch_tabular) (25.0)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>3.1->pytorch_tabular) (11.3.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>3.1->pytorch_tabular) (2.9.0.post0)\n","Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.12/dist-packages (from omegaconf>=2.3.0->pytorch_tabular) (4.9.3)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.1.5->pytorch_tabular) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.1.5->pytorch_tabular) (2025.2)\n","Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning<2.5.0,>=2.0.0->pytorch_tabular) (2025.3.0)\n","Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from pytorch-lightning<2.5.0,>=2.0.0->pytorch_tabular) (4.15.0)\n","Collecting lightning-utilities>=0.10.0 (from pytorch-lightning<2.5.0,>=2.0.0->pytorch_tabular)\n","  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=11.0.0->pytorch_tabular) (4.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=11.0.0->pytorch_tabular) (2.19.2)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.3.0->pytorch_tabular) (1.5.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.3.0->pytorch_tabular) (3.6.0)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard!=2.5.0,>2.2.0->pytorch_tabular) (1.4.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard!=2.5.0,>2.2.0->pytorch_tabular) (1.76.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard!=2.5.0,>2.2.0->pytorch_tabular) (3.10)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard!=2.5.0,>2.2.0->pytorch_tabular) (75.2.0)\n","Requirement already satisfied: six>1.9 in /usr/local/lib/python3.12/dist-packages (from tensorboard!=2.5.0,>2.2.0->pytorch_tabular) (1.17.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard!=2.5.0,>2.2.0->pytorch_tabular) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard!=2.5.0,>2.2.0->pytorch_tabular) (3.1.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->pytorch_tabular) (3.20.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->pytorch_tabular) (1.14.0)\n","Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->pytorch_tabular) (3.6)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->pytorch_tabular) (3.1.6)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->pytorch_tabular) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->pytorch_tabular) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->pytorch_tabular) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->pytorch_tabular) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->pytorch_tabular) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->pytorch_tabular) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->pytorch_tabular) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->pytorch_tabular) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->pytorch_tabular) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->pytorch_tabular) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->pytorch_tabular) (2.27.5)\n","Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->pytorch_tabular) (3.3.20)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->pytorch_tabular) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->pytorch_tabular) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->pytorch_tabular) (1.11.1.6)\n","Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->pytorch_tabular) (3.5.0)\n","Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.12/dist-packages (from ipywidgets->pytorch_tabular) (6.17.1)\n","Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets->pytorch_tabular) (0.2.0)\n","Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.12/dist-packages (from ipywidgets->pytorch_tabular) (5.7.1)\n","Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets->pytorch_tabular) (3.6.10)\n","Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets->pytorch_tabular) (7.34.0)\n","Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets->pytorch_tabular) (3.0.16)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning<2.5.0,>=2.0.0->pytorch_tabular) (3.13.2)\n","Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets->pytorch_tabular) (1.8.15)\n","Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets->pytorch_tabular) (7.4.9)\n","Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets->pytorch_tabular) (0.2.1)\n","Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets->pytorch_tabular) (1.6.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets->pytorch_tabular) (5.9.5)\n","Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets->pytorch_tabular) (26.2.1)\n","Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets->pytorch_tabular) (6.5.1)\n","Collecting jedi>=0.16 (from ipython>=4.0.0->ipywidgets->pytorch_tabular)\n","  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets->pytorch_tabular) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets->pytorch_tabular) (0.7.5)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets->pytorch_tabular) (3.0.52)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets->pytorch_tabular) (0.2.0)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets->pytorch_tabular) (4.9.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=11.0.0->pytorch_tabular) (0.1.2)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->pytorch_tabular) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard!=2.5.0,>2.2.0->pytorch_tabular) (3.0.3)\n","Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.12/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (6.5.7)\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<2.5.0,>=2.0.0->pytorch_tabular) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<2.5.0,>=2.0.0->pytorch_tabular) (1.4.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<2.5.0,>=2.0.0->pytorch_tabular) (1.8.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<2.5.0,>=2.0.0->pytorch_tabular) (6.7.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<2.5.0,>=2.0.0->pytorch_tabular) (0.4.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<2.5.0,>=2.0.0->pytorch_tabular) (1.22.0)\n","Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets->pytorch_tabular) (0.8.5)\n","Requirement already satisfied: entrypoints in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets->pytorch_tabular) (0.4)\n","Requirement already satisfied: jupyter-core>=4.9.2 in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets->pytorch_tabular) (5.9.1)\n","Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (25.1.0)\n","Requirement already satisfied: nbformat in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (5.10.4)\n","Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (7.16.6)\n","Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (1.8.3)\n","Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (0.18.1)\n","Requirement already satisfied: prometheus-client in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (0.23.1)\n","Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (1.3.3)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets->pytorch_tabular) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets->pytorch_tabular) (0.2.14)\n","Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.12/dist-packages (from jupyter-core>=4.9.2->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets->pytorch_tabular) (4.5.0)\n","Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.12/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (0.2.4)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (4.13.5)\n","Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (6.3.0)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (0.7.1)\n","Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (0.3.0)\n","Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (3.1.4)\n","Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (0.10.2)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (1.5.1)\n","Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.12/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (2.21.2)\n","Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.12/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (4.25.1)\n","Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.12/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<2.5.0,>=2.0.0->pytorch_tabular) (3.11)\n","Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.12/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (25.1.0)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (0.5.1)\n","Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (1.4.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (2025.9.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (0.37.0)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (0.29.0)\n","Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.12/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (2.14.0)\n","Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (2.0.0)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (2.8)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (2.23)\n","Requirement already satisfied: anyio>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (4.11.0)\n","Requirement already satisfied: jupyter-events>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (0.12.0)\n","Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (0.5.3)\n","Requirement already satisfied: overrides>=5.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (7.7.0)\n","Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (1.9.0)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (1.3.1)\n","Requirement already satisfied: python-json-logger>=2.0.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (4.0.0)\n","Requirement already satisfied: rfc3339-validator in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (0.1.4)\n","Requirement already satisfied: rfc3986-validator>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (0.1.1)\n","Requirement already satisfied: fqdn in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (1.5.1)\n","Requirement already satisfied: isoduration in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (20.11.0)\n","Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (3.0.0)\n","Requirement already satisfied: rfc3987-syntax>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (1.1.0)\n","Requirement already satisfied: uri-template in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (1.3.0)\n","Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (25.10.0)\n","Requirement already satisfied: lark>=1.2.2 in /usr/local/lib/python3.12/dist-packages (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (1.3.1)\n","Requirement already satisfied: arrow>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (1.4.0)\n","Downloading pytorch_tabular-1.1.1-py2.py3-none-any.whl (163 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.8/163.8 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pytorch_tabnet-4.1.0-py3-none-any.whl (44 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.5/44.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading einops-0.7.0-py3-none-any.whl (44 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m134.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading protobuf-5.28.3-cp38-abi3-manylinux2014_x86_64.whl (316 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.6/316.6 kB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pytorch_lightning-2.4.0-py3-none-any.whl (815 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.2/815.2 kB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torchmetrics-1.5.2-py3-none-any.whl (891 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m891.4/891.4 kB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n","Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m68.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: protobuf, numpy, lightning-utilities, jedi, einops, torchmetrics, pytorch-tabnet, pytorch-lightning, pytorch_tabular\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 5.29.5\n","    Uninstalling protobuf-5.29.5:\n","      Successfully uninstalled protobuf-5.29.5\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 2.0.2\n","    Uninstalling numpy-2.0.2:\n","      Successfully uninstalled numpy-2.0.2\n","  Attempting uninstall: einops\n","    Found existing installation: einops 0.8.1\n","    Uninstalling einops-0.8.1:\n","      Successfully uninstalled einops-0.8.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n","opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n","opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n","pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n","ydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 5.28.3 which is incompatible.\n","opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n","jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n","shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed einops-0.7.0 jedi-0.19.2 lightning-utilities-0.15.2 numpy-1.26.4 protobuf-5.28.3 pytorch-lightning-2.4.0 pytorch-tabnet-4.1.0 pytorch_tabular-1.1.1 torchmetrics-1.5.2\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["google","numpy"]},"id":"2f5a5721effa4b02921eeb5691066601"}},"metadata":{}}],"source":["!pip install rasterio pytorch_tabular"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8eU1-9B02emm"},"outputs":[],"source":["import os\n","import gc\n","import json\n","import glob\n","import joblib\n","import pickle\n","import rasterio\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","from tqdm import tqdm\n","from rasterio.transform import from_bounds\n","from sklearn.preprocessing import StandardScaler\n","\n","# Install pyproj if needed for coordinate transformation\n","try:\n","    from pyproj import Transformer\n","except:\n","    print(\"Installing pyproj...\")\n","    import subprocess\n","    subprocess.check_call(['pip', 'install', 'pyproj'])\n","    from pyproj import Transformer\n","\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","import tensorflow as tf\n","\n","from pytorch_tabular import TabularModel\n","from pytorch_tabular.models import FTTransformerConfig\n","from pytorch_tabular.config import DataConfig, OptimizerConfig, TrainerConfig"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1764315456805,"user":{"displayName":"Christian Candido","userId":"04121477428710958590"},"user_tz":-480},"id":"MLuZjFDR2p0P","outputId":"a21b9feb-eec4-4f7d-edc9-a6ff34a5222a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n"]}],"source":["# Check GPU\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(f\"Using device: {device}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mHK2oozq3THF"},"outputs":[],"source":["# VARIABLES\n","MODEL_PATH = '/content/drive/MyDrive/AGRI/Planting_Method/model/cnn-lstm/CNN-LSTM_dry_model.pth'\n","TFRECORD_DIR = '/content/drive/MyDrive/AGRI/Planting_Method/tfrecord'\n","OUTPUT_DIR = '/content/drive/MyDrive/AGRI/Planting_Method/results'\n","os.makedirs(OUTPUT_DIR, exist_ok=True)\n","\n","PATCH_SIZE = 256\n","BATCH_SIZE = 512\n","SEQUENCE_LENGTH = 18  # Number of timesteps\n","EXPECTED_BANDS = 1    # Single band per timestep: VH polarization"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sNt9jp87AZ0-"},"outputs":[],"source":["class SimplifiedCNNLSTM(nn.Module):\n","    \"\"\"\n","    CNN-LSTM architecture for better stability and convergence.\n","    Good for imbalanced SAR time-series data.\n","    \"\"\"\n","    def __init__(self, input_dim, hidden_dim=128, num_layers=2, num_classes=2, dropout_rate=0.3):\n","        super().__init__()\n","\n","        # Simpler CNN with fewer parameters\n","        self.cnn = nn.Sequential(\n","            nn.Conv1d(input_dim, 64, kernel_size=3, padding=1),\n","            nn.BatchNorm1d(64),\n","            nn.ReLU(),\n","            nn.Dropout(dropout_rate),\n","\n","            nn.Conv1d(64, 128, kernel_size=3, padding=1),\n","            nn.BatchNorm1d(128),\n","            nn.ReLU(),\n","            nn.Dropout(dropout_rate)\n","        )\n","\n","        # Bidirectional LSTM\n","        self.lstm = nn.LSTM(\n","            input_size=128,\n","            hidden_size=hidden_dim,\n","            num_layers=num_layers,\n","            batch_first=True,\n","            bidirectional=True,\n","            dropout=dropout_rate if num_layers > 1 else 0\n","        )\n","\n","        # Layer normalization\n","        self.ln = nn.LayerNorm(hidden_dim * 2)\n","\n","        # Simple attention\n","        self.attention = nn.Sequential(\n","            nn.Linear(hidden_dim * 2, 64),\n","            nn.Tanh(),\n","            nn.Linear(64, 1)\n","        )\n","\n","        # Classifier\n","        self.classifier = nn.Sequential(\n","            nn.Linear(hidden_dim * 2, hidden_dim),\n","            nn.ReLU(),\n","            nn.Dropout(dropout_rate),\n","            nn.Linear(hidden_dim, num_classes)\n","        )\n","\n","        # Initialize weights\n","        self._init_weights()\n","\n","    def _init_weights(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv1d):\n","                nn.init.kaiming_normal_(m.weight)\n","            elif isinstance(m, nn.Linear):\n","                nn.init.xavier_uniform_(m.weight)\n","                if m.bias is not None:\n","                    nn.init.constant_(m.bias, 0)\n","\n","    def forward(self, x):\n","        # CNN\n","        x = x.permute(0, 2, 1)\n","        cnn_out = self.cnn(x)\n","        cnn_out = cnn_out.permute(0, 2, 1)\n","\n","        # LSTM\n","        lstm_out, _ = self.lstm(cnn_out)\n","        lstm_out = self.ln(lstm_out)\n","\n","        # Attention\n","        attn_scores = self.attention(lstm_out)\n","        attn_weights = F.softmax(attn_scores, dim=1)\n","        context = torch.sum(attn_weights * lstm_out, dim=1)\n","\n","        # Classification\n","        return self.classifier(context)\n","\n","\n","class ResidualBlock(nn.Module):\n","    \"\"\"Residual CNN block with batch normalization\"\"\"\n","    def __init__(self, in_channels, out_channels, kernel_size=3, dropout=0.3):\n","        super().__init__()\n","\n","        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size, padding=kernel_size//2)\n","        self.bn1 = nn.BatchNorm1d(out_channels)\n","        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size, padding=kernel_size//2)\n","        self.bn2 = nn.BatchNorm1d(out_channels)\n","        self.dropout = nn.Dropout(dropout)\n","\n","        # Skip connection\n","        self.skip = nn.Conv1d(in_channels, out_channels, 1) if in_channels != out_channels else nn.Identity()\n","        self.bn_skip = nn.BatchNorm1d(out_channels) if in_channels != out_channels else nn.Identity()\n","\n","    def forward(self, x):\n","        identity = self.bn_skip(self.skip(x))\n","\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = F.leaky_relu(out, 0.1)\n","        out = self.dropout(out)\n","\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","\n","        out += identity  # Residual connection\n","        out = F.leaky_relu(out, 0.1)\n","\n","        return out\n","\n","\n","class SEBlock(nn.Module):\n","    \"\"\"Squeeze-and-Excitation block for channel attention\"\"\"\n","    def __init__(self, channels, reduction=16):\n","        super().__init__()\n","        self.squeeze = nn.AdaptiveAvgPool1d(1)\n","        self.excitation = nn.Sequential(\n","            nn.Linear(channels, channels // reduction, bias=False),\n","            nn.ReLU(inplace=True),\n","            nn.Linear(channels // reduction, channels, bias=False),\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, x):\n","        batch, channels, _ = x.size()\n","        y = self.squeeze(x).view(batch, channels)\n","        y = self.excitation(y).view(batch, channels, 1)\n","        return x * y.expand_as(x)\n","\n","\n","class PositionalEncoding(nn.Module):\n","    \"\"\"Positional encoding for temporal sequences\"\"\"\n","    def __init__(self, d_model, dropout=0.1, max_len=5000):\n","        super().__init__()\n","        self.dropout = nn.Dropout(p=dropout)\n","\n","        position = torch.arange(max_len).unsqueeze(1)\n","        div_term = torch.exp(torch.arange(0, d_model, 2) * (-np.log(10000.0) / d_model))\n","        pe = torch.zeros(1, max_len, d_model)\n","        pe[0, :, 0::2] = torch.sin(position * div_term)\n","        pe[0, :, 1::2] = torch.cos(position * div_term)\n","        self.register_buffer('pe', pe)\n","\n","    def forward(self, x):\n","        x = x + self.pe[:, :x.size(1), :]\n","        return self.dropout(x)\n","\n","def load_trained_model(model_path, model, device, load_optimizer=False, load_scheduler=False):\n","\n","    checkpoint = torch.load(model_path, map_location=device)\n","\n","    # Handle different checkpoint formats\n","    if 'model_state_dict' in checkpoint:\n","        # New format (from train_model_full)\n","        model.load_state_dict(checkpoint['model_state_dict'])\n","        print(f\"✓ Loaded model from epoch {checkpoint.get('epoch', 'unknown')}\")\n","        print(f\"✓ Best validation accuracy: {checkpoint.get('best_accuracy', 'unknown'):.4f}\")\n","    else:\n","        # Old format (direct state_dict)\n","        model.load_state_dict(checkpoint)\n","        print(f\"✓ Loaded model state_dict\")\n","\n","    model.to(device)\n","    model.eval()\n","\n","    return model, checkpoint"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2764,"status":"ok","timestamp":1764315497046,"user":{"displayName":"Christian Candido","userId":"04121477428710958590"},"user_tz":-480},"id":"lVgIdP3gAtb-","outputId":"24b7c798-6694-40a2-d952-515e34dfd332"},"outputs":[{"output_type":"stream","name":"stdout","text":["✓ Loaded model from epoch 224\n","✓ Best validation accuracy: 0.7981\n"]},{"output_type":"execute_result","data":{"text/plain":["SimplifiedCNNLSTM(\n","  (cnn): Sequential(\n","    (0): Conv1d(18, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n","    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","    (3): Dropout(p=0.4, inplace=False)\n","    (4): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n","    (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (6): ReLU()\n","    (7): Dropout(p=0.4, inplace=False)\n","  )\n","  (lstm): LSTM(128, 128, num_layers=2, batch_first=True, dropout=0.4, bidirectional=True)\n","  (ln): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","  (attention): Sequential(\n","    (0): Linear(in_features=256, out_features=64, bias=True)\n","    (1): Tanh()\n","    (2): Linear(in_features=64, out_features=1, bias=True)\n","  )\n","  (classifier): Sequential(\n","    (0): Linear(in_features=256, out_features=128, bias=True)\n","    (1): ReLU()\n","    (2): Dropout(p=0.4, inplace=False)\n","    (3): Linear(in_features=128, out_features=2, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":5}],"source":["# CNN-LSTM model\n","model = SimplifiedCNNLSTM(\n","         input_dim=18,\n","         hidden_dim=128,\n","         num_layers=2,\n","         num_classes=2,\n","         dropout_rate=0.4\n",").to(device)\n","\n","model_new, checkpoint = load_trained_model(\n","         model_path='/content/drive/MyDrive/AGRI/Planting_Method/model/CNN-LSTM_dry_model.pth',\n","         model=model,\n","         device=device\n",")\n","\n","model_new.to(device)\n","model_new.eval()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FnGhUx4U_5lY"},"outputs":[],"source":["# =============================\n","# PROCESS TFRECORD - CLASSIFICATION VERSION\n","# =============================\n","\n","def process_tfrecord_streaming_timeseries(tfrecord_base_pattern, model, scaler, tile_bounds,\n","                                          expected_bands=1, sequence_length=18):\n","    print(f\"\\nStreaming processing: {os.path.basename(tfrecord_base_pattern)}\")\n","\n","    # Find all TFRecord files\n","    tfrecord_files = sorted(glob.glob(f\"{tfrecord_base_pattern}-*.tfrecord.gz\"))\n","\n","    if not tfrecord_files:\n","        print(\"  ⚠️ No TFRecord files found!\")\n","        return None, None, None\n","\n","    print(f\"  Found {len(tfrecord_files)} file(s)\")\n","\n","    # Load mixer.json for grid information\n","    mixer_path = f\"{tfrecord_base_pattern}-mixer.json\"\n","    mixer = None\n","    if os.path.exists(mixer_path):\n","        with open(mixer_path, 'r') as f:\n","            mixer = json.load(f)\n","        print(f\"  ✓ Loaded mixer.json\")\n","\n","    if not mixer or 'patchesPerRow' not in mixer:\n","        print(\"  ⚠️ No valid mixer.json found\")\n","        return None, None, None\n","\n","    # Get grid dimensions\n","    patches_per_row = mixer['patchesPerRow']\n","    total_patches = mixer['totalPatches']\n","    num_rows = int(np.ceil(total_patches / patches_per_row))\n","\n","    print(f\"  Grid: {num_rows} rows × {patches_per_row} cols ({total_patches} patches)\")\n","\n","    # Calculate output dimensions\n","    output_h = num_rows * PATCH_SIZE\n","    output_w = patches_per_row * PATCH_SIZE\n","\n","    print(f\"  Output size: {output_h} × {output_w} pixels\")\n","\n","    # Calculate adjusted bounds\n","    min_lon, min_lat, max_lon, max_lat = tile_bounds\n","\n","    actual_pixel_size_lon = (max_lon - min_lon) / output_w\n","    actual_pixel_size_lat = (max_lat - min_lat) / output_h\n","\n","    actual_max_lon = min_lon + (output_w * actual_pixel_size_lon)\n","    actual_max_lat = min_lat + (output_h * actual_pixel_size_lat)\n","\n","    actual_bounds = [min_lon, min_lat, actual_max_lon, actual_max_lat]\n","\n","    print(f\"  Adjusted bounds: [{actual_bounds[0]:.6f}, {actual_bounds[1]:.6f}, \"\n","          f\"{actual_bounds[2]:.6f}, {actual_bounds[3]:.6f}]\")\n","\n","    # Initialize output arrays - use 255 as nodata for uint8\n","    classification_map = np.full((output_h, output_w), 255, dtype=np.uint8)\n","    confidence_map = np.zeros((output_h, output_w), dtype=np.float32)\n","\n","    # Band names for your S1 VH time series\n","    band_names_ordered = [f\"{t}_VH\" for t in range(sequence_length)]\n","\n","    # Track missing bands\n","    missing_bands_count = 0\n","\n","    # Process patches\n","    patch_idx = 0\n","    total_valid_pixels = 0\n","\n","    for file_idx, tfrecord_file in enumerate(tfrecord_files):\n","        print(f\"  Processing file {file_idx+1}/{len(tfrecord_files)}\")\n","\n","        dataset = tf.data.TFRecordDataset(tfrecord_file, compression_type='GZIP')\n","\n","        for raw_record in dataset:\n","            # Parse TFRecord\n","            example = tf.train.Example()\n","            example.ParseFromString(raw_record.numpy())\n","            features = example.features.feature\n","\n","            # Extract time series data with interpolation for missing bands\n","            patch_timeseries = []\n","            available_bands = {}\n","\n","            # First pass: collect all available bands\n","            for band_name in band_names_ordered:\n","                if band_name in features:\n","                    values = np.array(features[band_name].float_list.value)\n","                    timestep_patch = values.reshape(PATCH_SIZE, PATCH_SIZE, 1)\n","                    available_bands[band_name] = timestep_patch\n","\n","            # If we're missing bands, interpolate\n","            if len(available_bands) < sequence_length:\n","                missing_bands_count += 1\n","\n","                # Second pass: interpolate missing bands\n","                for i, band_name in enumerate(band_names_ordered):\n","                    if band_name in available_bands:\n","                        patch_timeseries.append(available_bands[band_name])\n","                    else:\n","                        # Find nearest neighbors for interpolation\n","                        prev_idx = i - 1\n","                        next_idx = i + 1\n","\n","                        # Search backward for valid band\n","                        while prev_idx >= 0 and band_names_ordered[prev_idx] not in available_bands:\n","                            prev_idx -= 1\n","\n","                        # Search forward for valid band\n","                        while next_idx < sequence_length and band_names_ordered[next_idx] not in available_bands:\n","                            next_idx += 1\n","\n","                        # Interpolate\n","                        if prev_idx >= 0 and next_idx < sequence_length:\n","                            prev_band = available_bands[band_names_ordered[prev_idx]]\n","                            next_band = available_bands[band_names_ordered[next_idx]]\n","                            weight = (i - prev_idx) / (next_idx - prev_idx)\n","                            interpolated = prev_band * (1 - weight) + next_band * weight\n","                            patch_timeseries.append(interpolated)\n","                        elif prev_idx >= 0:\n","                            patch_timeseries.append(available_bands[band_names_ordered[prev_idx]])\n","                        elif next_idx < sequence_length:\n","                            patch_timeseries.append(available_bands[band_names_ordered[next_idx]])\n","                        else:\n","                            patch_timeseries = None\n","                            break\n","            else:\n","                # All bands available\n","                patch_timeseries = [available_bands[bn] for bn in band_names_ordered]\n","\n","            if patch_timeseries is None or len(patch_timeseries) != sequence_length:\n","                patch_idx += 1\n","                continue\n","\n","            # Stack timesteps: (seq_len, PATCH_SIZE, PATCH_SIZE, 1)\n","            patch = np.stack(patch_timeseries, axis=0)\n","\n","            # Calculate patch position in output grid\n","            row_idx = patch_idx // patches_per_row\n","            col_idx = patch_idx % patches_per_row\n","\n","            start_h = row_idx * PATCH_SIZE\n","            start_w = col_idx * PATCH_SIZE\n","\n","            # Reshape to pixels: (seq_len, n_pixels, num_bands)\n","            pixels_per_patch = PATCH_SIZE * PATCH_SIZE\n","            pixels = patch.reshape(sequence_length, pixels_per_patch, expected_bands)\n","\n","            # Transpose to: (n_pixels, seq_len, num_bands)\n","            pixels = np.transpose(pixels, (1, 0, 2))\n","\n","            # Find valid pixels (no NaN or 0 across all timesteps)\n","            valid_mask = ~np.any(np.isnan(pixels) | (pixels == 0), axis=(1, 2))\n","            valid_indices = np.where(valid_mask)[0]\n","            n_valid = len(valid_indices)\n","\n","            if n_valid > 0:\n","                total_valid_pixels += n_valid\n","\n","                # Normalize if scaler is provided\n","                if scaler is not None:\n","                    valid_pixels_flat = pixels[valid_indices].reshape(-1, expected_bands)\n","\n","                    import warnings\n","                    with warnings.catch_warnings():\n","                        warnings.filterwarnings('ignore')\n","                        scaled_flat = scaler.transform(valid_pixels_flat)\n","\n","                    valid_features = scaled_flat.reshape(n_valid, sequence_length, expected_bands)\n","                else:\n","                    valid_features = pixels[valid_indices]\n","\n","                # Initialize prediction arrays\n","                patch_classes = np.full(pixels_per_patch, 255, dtype=np.uint8)  # 255 = nodata\n","                patch_conf = np.zeros(pixels_per_patch, dtype=np.float32)\n","\n","                # Process in batches\n","                for start_idx in range(0, n_valid, BATCH_SIZE):\n","                    end_idx = min(start_idx + BATCH_SIZE, n_valid)\n","                    batch_indices = valid_indices[start_idx:end_idx]\n","\n","                    batch_features = valid_features[start_idx:end_idx]\n","\n","                    # Convert to PyTorch tensor: (batch_size, seq_len, num_bands)\n","                    # batch_tensor = torch.from_numpy(batch_features).float().to(device)\n","\n","                    batch_features_reshaped = batch_features.squeeze(-1)  # Remove last dim: (n_valid, 18, 1) -> (n_valid, 18)\n","                    batch_tensor = torch.from_numpy(batch_features_reshaped).float().to(device)\n","                    # Shape: (batch_size, 18)\n","\n","                    # Add feature dimension for model\n","                    batch_tensor = batch_tensor.unsqueeze(1)  # (batch_size, 18) -> (batch_size, 1, 18)\n","                    # Now shape is (batch_size, num_features=1, seq_len=18)\n","\n","                    # Predict with PyTorch model\n","                    with torch.no_grad():\n","                        outputs = model(batch_tensor)  # (batch_size, num_classes)\n","                        probs = torch.softmax(outputs, dim=1)\n","\n","                        # Get predicted class (0 or 1)\n","                        predicted_classes = torch.argmax(probs, dim=1).cpu().numpy()\n","\n","                        # Confidence: max probability\n","                        confidences = torch.max(probs, dim=1)[0].cpu().numpy()\n","\n","                    patch_classes[batch_indices] = predicted_classes\n","                    patch_conf[batch_indices] = confidences\n","\n","                # Reshape and store results\n","                patch_class_map = patch_classes.reshape(PATCH_SIZE, PATCH_SIZE)\n","                patch_conf_map = patch_conf.reshape(PATCH_SIZE, PATCH_SIZE)\n","\n","                classification_map[start_h:start_h+PATCH_SIZE, start_w:start_w+PATCH_SIZE] = patch_class_map\n","                confidence_map[start_h:start_h+PATCH_SIZE, start_w:start_w+PATCH_SIZE] = patch_conf_map\n","\n","            # Clean up\n","            del patch, pixels\n","\n","            patch_idx += 1\n","\n","            # Progress update\n","            if patch_idx % 50 == 0:\n","                progress = (patch_idx / total_patches) * 100\n","                print(f\"    Progress: {progress:.1f}% ({patch_idx}/{total_patches})\")\n","\n","            # Memory cleanup\n","            if patch_idx % 20 == 0:\n","                gc.collect()\n","                if torch.cuda.is_available():\n","                    torch.cuda.empty_cache()\n","\n","    print(f\"  ✓ Processed all {patch_idx} patches\")\n","\n","    if missing_bands_count > 0:\n","        print(f\"  ⚠️ Interpolated missing bands in {missing_bands_count} patches\")\n","\n","    # Statistics\n","    valid_mask = classification_map != 255\n","    valid_classes = classification_map[valid_mask]\n","\n","    if len(valid_classes) > 0:\n","        # Basic statistics\n","        n_direct = (valid_classes == 0).sum()\n","        n_transplanted = (valid_classes == 1).sum()\n","\n","        # Confidence-based statistics\n","        valid_confidence = confidence_map[valid_mask]\n","        high_conf_mask = valid_confidence >= 0.6  # Filter by confidence threshold\n","\n","        high_conf_classes = valid_classes[high_conf_mask]\n","        n_high_conf = len(high_conf_classes)\n","\n","        if n_high_conf > 0:\n","            n_direct_highconf = (high_conf_classes == 0).sum()\n","            n_transplanted_highconf = (high_conf_classes == 1).sum()\n","        else:\n","            n_direct_highconf = 0\n","            n_transplanted_highconf = 0\n","\n","        print(f\"\\n  Classification Statistics:\")\n","        print(f\"    Total valid pixels: {len(valid_classes):,}\")\n","        print(f\"    \")\n","        print(f\"    All Predictions:\")\n","        print(f\"      Class 0 (Direct-Seeded): {n_direct:,} ({n_direct/len(valid_classes)*100:.1f}%)\")\n","        print(f\"      Class 1 (Transplanted):  {n_transplanted:,} ({n_transplanted/len(valid_classes)*100:.1f}%)\")\n","        print(f\"    \")\n","        print(f\"    High Confidence (≥0.6) Predictions:\")\n","        print(f\"      Total: {n_high_conf:,} ({n_high_conf/len(valid_classes)*100:.1f}%)\")\n","        if n_high_conf > 0:\n","            print(f\"      Class 0 (Direct-Seeded): {n_direct_highconf:,} ({n_direct_highconf/n_high_conf*100:.1f}%)\")\n","            print(f\"      Class 1 (Transplanted):  {n_transplanted_highconf:,} ({n_transplanted_highconf/n_high_conf*100:.1f}%)\")\n","        print(f\"    \")\n","        print(f\"    Confidence Statistics:\")\n","        print(f\"      Mean confidence:  {valid_confidence.mean():.3f}\")\n","        print(f\"      Median confidence: {np.median(valid_confidence):.3f}\")\n","        print(f\"      Min confidence:   {valid_confidence.min():.3f}\")\n","        print(f\"      Max confidence:   {valid_confidence.max():.3f}\")\n","\n","    return classification_map, confidence_map, actual_bounds"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yeeVhgcO7N9O"},"outputs":[],"source":["# =============================\n","# SAVE GEOTIFF\n","# =============================\n","\n","def save_geotiff_aligned(array, output_path, bounds, crs):\n","    \"\"\"Save array as GeoTIFF with proper georeferencing\"\"\"\n","    h, w = array.shape\n","\n","    min_x, min_y, max_x, max_y = bounds\n","\n","    pixel_width = (max_x - min_x) / w\n","    pixel_height = (max_y - min_y) / h\n","\n","    transform = rasterio.transform.from_bounds(\n","        min_x, min_y, max_x, max_y, w, h\n","    )\n","\n","    print(f\"    Saving: {os.path.basename(output_path)}\")\n","    print(f\"      Size: {w} x {h}\")\n","    print(f\"      Bounds: {bounds}\")\n","\n","\n","\n","    with rasterio.open(\n","        output_path, 'w',\n","        driver='GTiff',\n","        height=h,\n","        width=w,\n","        count=1,\n","        dtype=np.float32,\n","        crs=crs,\n","        transform=transform,\n","        compress='lzw',\n","        nodata=-9999\n","    ) as dst:\n","        dst.write(array, 1)\n","\n","    print(f\"    ✓ Saved\")\n","\n","\n","# =============================\n","# READ TILE MIXER\n","# =============================\n","\n","def read_tile_mixer(tile_base_path):\n","    \"\"\"Read mixer.json and extract georeferencing info\"\"\"\n","    mixer_path = f\"{tile_base_path}-mixer.json\"\n","\n","    if not os.path.exists(mixer_path):\n","        raise FileNotFoundError(f\"mixer.json not found: {mixer_path}\")\n","\n","    with open(mixer_path, 'r') as f:\n","        mixer = json.load(f)\n","\n","    # Extract info\n","    crs = mixer['projection']['crs']\n","    patch_dims = mixer.get('patchDimensions', [256, 256])\n","    patches_per_row = mixer.get('patchesPerRow', 0)\n","    total_patches = mixer.get('totalPatches', 0)\n","\n","    patches_per_col = total_patches // patches_per_row if patches_per_row > 0 else 0\n","\n","    # Extract affine transform\n","    affine_matrix = mixer['projection']['affine']['doubleMatrix']\n","\n","    scale_x = affine_matrix[0]\n","    translate_x = affine_matrix[2]\n","    scale_y = affine_matrix[4]\n","    translate_y = affine_matrix[5]\n","\n","    # Calculate bounds\n","    patch_width_pixels = patch_dims[0]\n","    patch_height_pixels = patch_dims[1]\n","\n","    total_width_pixels = patches_per_row * patch_width_pixels\n","    total_height_pixels = patches_per_col * patch_height_pixels\n","\n","    min_x = translate_x\n","    max_y = translate_y\n","    max_x = min_x + (total_width_pixels * scale_x)\n","    min_y = max_y + (total_height_pixels * scale_y)\n","\n","    bounds = [min_x, min_y, max_x, max_y]\n","\n","    return {\n","        'crs': crs,\n","        'mixer': mixer,\n","        'patch_dims': patch_dims,\n","        'bounds': bounds,\n","        'grid_size': (patches_per_row, patches_per_col),\n","        'pixel_size': (scale_x, abs(scale_y))\n","    }"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3247,"status":"ok","timestamp":1764315504096,"user":{"displayName":"Christian Candido","userId":"04121477428710958590"},"user_tz":-480},"id":"GMiMro4k1Vej","outputId":"3c84ddc2-afe4-4220-e57d-71663cb8924a"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","======================================================================\n","DISCOVERING TILES\n","======================================================================\n","\n","Found 4 unique tiles\n","\n","  Tile 1: S1_composite_dry2025_tile_001\n","    CRS: EPSG:4326\n","    Grid: 23 x 23\n","    Bounds: [120.75702021457921, 15.787531792286941, 121.28594825386878, 16.316459831576516]\n","\n","  Tile 2: S1_composite_dry2025_tile_002\n","    CRS: EPSG:4326\n","    Grid: 23 x 21\n","    Bounds: [120.75702021457921, 16.2840306498198, 121.28594825386878, 16.766964946562457]\n","\n","  Tile 4: S1_composite_dry2025_tile_004\n","    CRS: EPSG:4326\n","    Grid: 13 x 23\n","    Bounds: [121.25702250172013, 15.787352129230118, 121.55598182827511, 16.316280168519693]\n","\n","  Tile 5: S1_composite_dry2025_tile_005\n","    CRS: EPSG:4326\n","    Grid: 13 x 21\n","    Bounds: [121.25702250172013, 16.283940818291388, 121.55598182827511, 16.766875115034043]\n","\n","✓ Loaded 4 tiles with georeferencing\n"]}],"source":["# =============================\n","# TILE LOADING\n","# =============================\n","\n","print(\"\\n\" + \"=\"*70)\n","print(\"DISCOVERING TILES\")\n","print(\"=\"*70)\n","\n","# Find tiles\n","all_files = glob.glob(f\"{TFRECORD_DIR}/*.tfrecord.gz\")\n","tile_bases = set()\n","\n","for file in all_files:\n","    basename = os.path.basename(file)\n","    base = basename.rsplit('-', 1)[0]\n","    tile_bases.add(os.path.join(TFRECORD_DIR, base))\n","\n","tile_bases = sorted(tile_bases)\n","print(f\"\\nFound {len(tile_bases)} unique tiles\")\n","\n","# Read mixer.json for each tile\n","tile_info = []\n","\n","for tile_base in tile_bases:\n","    basename = os.path.basename(tile_base)\n","\n","    # Extract tile number\n","    import re\n","    match = re.search(r'tile[_-](\\d+)', basename)\n","    tile_num = int(match.group(1)) if match else None\n","\n","    try:\n","        mixer_data = read_tile_mixer(tile_base)\n","\n","        tile_info.append({\n","            'base': tile_base,\n","            'number': tile_num,\n","            'bounds': mixer_data['bounds'],\n","            'crs': mixer_data['crs'],\n","            'mixer': mixer_data['mixer'],\n","            'grid_size': mixer_data['grid_size'],\n","            'pixel_size': mixer_data['pixel_size']\n","        })\n","\n","        print(f\"\\n  Tile {tile_num}: {basename}\")\n","        print(f\"    CRS: {mixer_data['crs']}\")\n","        print(f\"    Grid: {mixer_data['grid_size'][0]} x {mixer_data['grid_size'][1]}\")\n","        print(f\"    Bounds: {mixer_data['bounds']}\")\n","\n","    except Exception as e:\n","        print(f\"\\n  ⚠ Error: {e}\")\n","        continue\n","\n","print(f\"\\n✓ Loaded {len(tile_info)} tiles with georeferencing\")\n","\n","if len(tile_info) == 0:\n","    raise ValueError(\"No valid tiles found!\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GT1weN3Z8t0G","outputId":"b257d3e3-6376-43c8-984e-fcec412413f1","executionInfo":{"status":"ok","timestamp":1764315987529,"user_tz":-480,"elapsed":469969,"user":{"displayName":"Christian Candido","userId":"04121477428710958590"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","======================================================================\n","PROCESSING TILES FOR CLASSIFICATION\n","======================================================================\n","\n","======================================================================\n","TILE 1 (1/4)\n","Base: S1_composite_dry2025_tile_001\n","CRS: EPSG:4326\n","Bounds: [120.75702021457921, 15.787531792286941, 121.28594825386878, 16.316459831576516]\n","======================================================================\n","\n","Streaming processing: S1_composite_dry2025_tile_001\n","  Found 25 file(s)\n","  ✓ Loaded mixer.json\n","  Grid: 23 rows × 23 cols (529 patches)\n","  Output size: 5888 × 5888 pixels\n","  Adjusted bounds: [120.757020, 15.787532, 121.285948, 16.316460]\n","  Processing file 1/25\n","  Processing file 2/25\n","  Processing file 3/25\n","    Progress: 9.5% (50/529)\n","  Processing file 4/25\n","  Processing file 5/25\n","    Progress: 18.9% (100/529)\n","  Processing file 6/25\n","  Processing file 7/25\n","    Progress: 28.4% (150/529)\n","  Processing file 8/25\n","  Processing file 9/25\n","  Processing file 10/25\n","    Progress: 37.8% (200/529)\n","  Processing file 11/25\n","  Processing file 12/25\n","    Progress: 47.3% (250/529)\n","  Processing file 13/25\n","  Processing file 14/25\n","    Progress: 56.7% (300/529)\n","  Processing file 15/25\n","  Processing file 16/25\n","    Progress: 66.2% (350/529)\n","  Processing file 17/25\n","  Processing file 18/25\n","  Processing file 19/25\n","    Progress: 75.6% (400/529)\n","  Processing file 20/25\n","  Processing file 21/25\n","    Progress: 85.1% (450/529)\n","  Processing file 22/25\n","  Processing file 23/25\n","    Progress: 94.5% (500/529)\n","  Processing file 24/25\n","  Processing file 25/25\n","  ✓ Processed all 529 patches\n","\n","  Classification Statistics:\n","    Total valid pixels: 4,948,792\n","    \n","    All Predictions:\n","      Class 0 (Direct-Seeded): 1,298,692 (26.2%)\n","      Class 1 (Transplanted):  3,650,100 (73.8%)\n","    \n","    High Confidence (≥0.6) Predictions:\n","      Total: 3,986,130 (80.5%)\n","      Class 0 (Direct-Seeded): 854,143 (21.4%)\n","      Class 1 (Transplanted):  3,131,987 (78.6%)\n","    \n","    Confidence Statistics:\n","      Mean confidence:  0.723\n","      Median confidence: 0.742\n","      Min confidence:   0.500\n","      Max confidence:   0.953\n","\n","  Tile Statistics:\n","    Valid pixels:        4,948,792\n","    Direct-Seeded (0):   1,298,692 (26.2%)\n","    Transplanted (1):    3,650,100 (73.8%)\n","    Mean confidence:     0.723\n","\n","  Saving outputs...\n","    Saving: tile_001_classification.tif\n","      Size: 5888 x 5888\n","      Bounds: [120.75702021457921, 15.787531792286941, 121.28594825386878, 16.316459831576516]\n","    ✓ Saved\n","    Saving: tile_001_confidence.tif\n","      Size: 5888 x 5888\n","      Bounds: [120.75702021457921, 15.787531792286941, 121.28594825386878, 16.316459831576516]\n","    ✓ Saved\n","  Creating visualization...\n","  ✓ Saved all outputs\n","\n","======================================================================\n","TILE 2 (2/4)\n","Base: S1_composite_dry2025_tile_002\n","CRS: EPSG:4326\n","Bounds: [120.75702021457921, 16.2840306498198, 121.28594825386878, 16.766964946562457]\n","======================================================================\n","\n","Streaming processing: S1_composite_dry2025_tile_002\n","  Found 22 file(s)\n","  ✓ Loaded mixer.json\n","  Grid: 21 rows × 23 cols (483 patches)\n","  Output size: 5376 × 5888 pixels\n","  Adjusted bounds: [120.757020, 16.284031, 121.285948, 16.766965]\n","  Processing file 1/22\n","  Processing file 2/22\n","  Processing file 3/22\n","    Progress: 10.4% (50/483)\n","  Processing file 4/22\n","  Processing file 5/22\n","    Progress: 20.7% (100/483)\n","  Processing file 6/22\n","  Processing file 7/22\n","    Progress: 31.1% (150/483)\n","  Processing file 8/22\n","  Processing file 9/22\n","  Processing file 10/22\n","    Progress: 41.4% (200/483)\n","  Processing file 11/22\n","  Processing file 12/22\n","    Progress: 51.8% (250/483)\n","  Processing file 13/22\n","  Processing file 14/22\n","    Progress: 62.1% (300/483)\n","  Processing file 15/22\n","  Processing file 16/22\n","    Progress: 72.5% (350/483)\n","  Processing file 17/22\n","  Processing file 18/22\n","  Processing file 19/22\n","    Progress: 82.8% (400/483)\n","  Processing file 20/22\n","  Processing file 21/22\n","    Progress: 93.2% (450/483)\n","  Processing file 22/22\n","  ✓ Processed all 483 patches\n","\n","  Classification Statistics:\n","    Total valid pixels: 3,062,680\n","    \n","    All Predictions:\n","      Class 0 (Direct-Seeded): 1,244,025 (40.6%)\n","      Class 1 (Transplanted):  1,818,655 (59.4%)\n","    \n","    High Confidence (≥0.6) Predictions:\n","      Total: 2,369,951 (77.4%)\n","      Class 0 (Direct-Seeded): 900,739 (38.0%)\n","      Class 1 (Transplanted):  1,469,212 (62.0%)\n","    \n","    Confidence Statistics:\n","      Mean confidence:  0.708\n","      Median confidence: 0.718\n","      Min confidence:   0.500\n","      Max confidence:   0.949\n","\n","  Tile Statistics:\n","    Valid pixels:        3,062,680\n","    Direct-Seeded (0):   1,244,025 (40.6%)\n","    Transplanted (1):    1,818,655 (59.4%)\n","    Mean confidence:     0.708\n","\n","  Saving outputs...\n","    Saving: tile_002_classification.tif\n","      Size: 5888 x 5376\n","      Bounds: [120.75702021457921, 16.2840306498198, 121.28594825386878, 16.766964946562457]\n","    ✓ Saved\n","    Saving: tile_002_confidence.tif\n","      Size: 5888 x 5376\n","      Bounds: [120.75702021457921, 16.2840306498198, 121.28594825386878, 16.766964946562457]\n","    ✓ Saved\n","  Creating visualization...\n","  ✓ Saved all outputs\n","\n","======================================================================\n","TILE 4 (3/4)\n","Base: S1_composite_dry2025_tile_004\n","CRS: EPSG:4326\n","Bounds: [121.25702250172013, 15.787352129230118, 121.55598182827511, 16.316280168519693]\n","======================================================================\n","\n","Streaming processing: S1_composite_dry2025_tile_004\n","  Found 14 file(s)\n","  ✓ Loaded mixer.json\n","  Grid: 23 rows × 13 cols (299 patches)\n","  Output size: 5888 × 3328 pixels\n","  Adjusted bounds: [121.257023, 15.787352, 121.555982, 16.316280]\n","  Processing file 1/14\n","  Processing file 2/14\n","  Processing file 3/14\n","    Progress: 16.7% (50/299)\n","  Processing file 4/14\n","  Processing file 5/14\n","    Progress: 33.4% (100/299)\n","  Processing file 6/14\n","  Processing file 7/14\n","    Progress: 50.2% (150/299)\n","  Processing file 8/14\n","  Processing file 9/14\n","  Processing file 10/14\n","    Progress: 66.9% (200/299)\n","  Processing file 11/14\n","  Processing file 12/14\n","    Progress: 83.6% (250/299)\n","  Processing file 13/14\n","  Processing file 14/14\n","  ✓ Processed all 299 patches\n","\n","  Classification Statistics:\n","    Total valid pixels: 526,875\n","    \n","    All Predictions:\n","      Class 0 (Direct-Seeded): 247,099 (46.9%)\n","      Class 1 (Transplanted):  279,776 (53.1%)\n","    \n","    High Confidence (≥0.6) Predictions:\n","      Total: 395,812 (75.1%)\n","      Class 0 (Direct-Seeded): 181,497 (45.9%)\n","      Class 1 (Transplanted):  214,315 (54.1%)\n","    \n","    Confidence Statistics:\n","      Mean confidence:  0.693\n","      Median confidence: 0.698\n","      Min confidence:   0.500\n","      Max confidence:   0.940\n","\n","  Tile Statistics:\n","    Valid pixels:        526,875\n","    Direct-Seeded (0):   247,099 (46.9%)\n","    Transplanted (1):    279,776 (53.1%)\n","    Mean confidence:     0.693\n","\n","  Saving outputs...\n","    Saving: tile_004_classification.tif\n","      Size: 3328 x 5888\n","      Bounds: [121.25702250172013, 15.787352129230118, 121.55598182827511, 16.316280168519693]\n","    ✓ Saved\n","    Saving: tile_004_confidence.tif\n","      Size: 3328 x 5888\n","      Bounds: [121.25702250172013, 15.787352129230118, 121.55598182827511, 16.316280168519693]\n","    ✓ Saved\n","  Creating visualization...\n","  ✓ Saved all outputs\n","\n","======================================================================\n","TILE 5 (4/4)\n","Base: S1_composite_dry2025_tile_005\n","CRS: EPSG:4326\n","Bounds: [121.25702250172013, 16.283940818291388, 121.55598182827511, 16.766875115034043]\n","======================================================================\n","\n","Streaming processing: S1_composite_dry2025_tile_005\n","  Found 13 file(s)\n","  ✓ Loaded mixer.json\n","  Grid: 21 rows × 13 cols (273 patches)\n","  Output size: 5376 × 3328 pixels\n","  Adjusted bounds: [121.257023, 16.283941, 121.555982, 16.766875]\n","  Processing file 1/13\n","  Processing file 2/13\n","  Processing file 3/13\n","    Progress: 18.3% (50/273)\n","  Processing file 4/13\n","  Processing file 5/13\n","    Progress: 36.6% (100/273)\n","  Processing file 6/13\n","  Processing file 7/13\n","    Progress: 54.9% (150/273)\n","  Processing file 8/13\n","  Processing file 9/13\n","  Processing file 10/13\n","    Progress: 73.3% (200/273)\n","  Processing file 11/13\n","  Processing file 12/13\n","    Progress: 91.6% (250/273)\n","  Processing file 13/13\n","  ✓ Processed all 273 patches\n","\n","  Classification Statistics:\n","    Total valid pixels: 2,958,116\n","    \n","    All Predictions:\n","      Class 0 (Direct-Seeded): 1,010,116 (34.1%)\n","      Class 1 (Transplanted):  1,948,000 (65.9%)\n","    \n","    High Confidence (≥0.6) Predictions:\n","      Total: 2,347,438 (79.4%)\n","      Class 0 (Direct-Seeded): 723,239 (30.8%)\n","      Class 1 (Transplanted):  1,624,199 (69.2%)\n","    \n","    Confidence Statistics:\n","      Mean confidence:  0.713\n","      Median confidence: 0.728\n","      Min confidence:   0.500\n","      Max confidence:   0.950\n","\n","  Tile Statistics:\n","    Valid pixels:        2,958,116\n","    Direct-Seeded (0):   1,010,116 (34.1%)\n","    Transplanted (1):    1,948,000 (65.9%)\n","    Mean confidence:     0.713\n","\n","  Saving outputs...\n","    Saving: tile_005_classification.tif\n","      Size: 3328 x 5376\n","      Bounds: [121.25702250172013, 16.283940818291388, 121.55598182827511, 16.766875115034043]\n","    ✓ Saved\n","    Saving: tile_005_confidence.tif\n","      Size: 3328 x 5376\n","      Bounds: [121.25702250172013, 16.283940818291388, 121.55598182827511, 16.766875115034043]\n","    ✓ Saved\n","  Creating visualization...\n","  ✓ Saved all outputs\n"]}],"source":["# =============================\n","# MAIN PROCESSING LOOP\n","# =============================\n","print(\"\\n\" + \"=\"*70)\n","print(\"PROCESSING TILES FOR CLASSIFICATION\")\n","print(\"=\"*70)\n","\n","results = []\n","\n","for idx, tile_data in enumerate(tile_info):\n","    tile_base = tile_data['base']\n","    bounds = tile_data['bounds']\n","    tile_num = tile_data['number']\n","    crs = tile_data['crs']\n","\n","    print(f\"\\n{'='*70}\")\n","    print(f\"TILE {tile_num} ({idx+1}/{len(tile_info)})\")\n","    print(f\"Base: {os.path.basename(tile_base)}\")\n","    print(f\"CRS: {crs}\")\n","    print(f\"Bounds: {bounds}\")\n","    print('='*70)\n","\n","    tile_name = f\"tile_{tile_num:03d}\"\n","\n","    try:\n","        # Process tile\n","        class_map, confidence_map, actual_bounds = process_tfrecord_streaming_timeseries(\n","            tile_base, model_new, None, bounds, EXPECTED_BANDS, SEQUENCE_LENGTH\n","        )\n","\n","        if class_map is None:\n","            print(\"  ⚠️ Failed to process\")\n","            continue\n","\n","        # Actual bounds\n","        if actual_bounds:\n","            bounds = actual_bounds\n","\n","        # Statistics\n","        valid_mask = class_map != 255\n","        valid_classes = class_map[valid_mask]\n","\n","        if len(valid_classes) > 0:\n","            n_direct = (valid_classes == 0).sum()\n","            n_transplanted = (valid_classes == 1).sum()\n","            pct_direct = (n_direct / len(valid_classes)) * 100\n","            pct_transplanted = (n_transplanted / len(valid_classes)) * 100\n","            mean_conf = confidence_map[valid_mask].mean()\n","\n","            print(f\"\\n  Tile Statistics:\")\n","            print(f\"    Valid pixels:        {len(valid_classes):,}\")\n","            print(f\"    Direct-Seeded (0):   {n_direct:,} ({pct_direct:.1f}%)\")\n","            print(f\"    Transplanted (1):    {n_transplanted:,} ({pct_transplanted:.1f}%)\")\n","            print(f\"    Mean confidence:     {mean_conf:.3f}\")\n","\n","            results.append({\n","                'tile': tile_num,\n","                'valid_pixels': len(valid_classes),\n","                'direct_seeded_count': n_direct,\n","                'transplanted_count': n_transplanted,\n","                'direct_seeded_pct': pct_direct,\n","                'transplanted_pct': pct_transplanted,\n","                'mean_confidence': mean_conf\n","            })\n","\n","        # Save outputs\n","        print(f\"\\n  Saving outputs...\")\n","        save_geotiff_aligned(\n","            class_map,\n","            f\"{OUTPUT_DIR}/{tile_name}_classification.tif\",\n","            bounds,\n","            crs\n","        )\n","        save_geotiff_aligned(\n","            confidence_map,\n","            f\"{OUTPUT_DIR}/{tile_name}_confidence.tif\",\n","            bounds,\n","            crs\n","        )\n","\n","        # Create visualization\n","        print(f\"  Creating visualization...\")\n","\n","        fig, axes = plt.subplots(1, 2, figsize=(16, 7))\n","\n","        # Classification map with custom colors\n","        class_vis = np.ma.masked_where(class_map == 255, class_map)\n","\n","        from matplotlib.colors import ListedColormap\n","        colors = ['#2ecc71', '#e67e22']  # Green for Direct-Seeded, Orange for Transplanted\n","        cmap_class = ListedColormap(colors)\n","\n","        im1 = axes[0].imshow(class_vis, cmap=cmap_class, vmin=0, vmax=1, interpolation='nearest')\n","        axes[0].set_title(f'Rice Planting Method Classification (Tile {tile_num})', fontsize=14, fontweight='bold')\n","        axes[0].axis('off')\n","\n","        # Custom legend\n","        from matplotlib.patches import Patch\n","        legend_elements = [\n","            Patch(facecolor='#2ecc71', label=f'Direct-Seeded ({n_direct:,} pixels, {pct_direct:.1f}%)'),\n","            Patch(facecolor='#e67e22', label=f'Transplanted ({n_transplanted:,} pixels, {pct_transplanted:.1f}%)'),\n","            Patch(facecolor='white', edgecolor='black', label=f'No Data')\n","        ]\n","        axes[0].legend(handles=legend_elements, loc='upper right', fontsize=10)\n","\n","        # Confidence map\n","        conf_vis = np.ma.masked_where(class_map == 255, confidence_map)\n","        im2 = axes[1].imshow(conf_vis, cmap='RdYlGn', vmin=0, vmax=1)\n","        axes[1].set_title('Prediction Confidence', fontsize=14, fontweight='bold')\n","        axes[1].axis('off')\n","        cbar2 = plt.colorbar(im2, ax=axes[1], fraction=0.046)\n","        cbar2.set_label('Confidence', rotation=270, labelpad=20, fontsize=11)\n","\n","        if len(valid_classes) > 0:\n","            plt.suptitle(\n","                f'Classification Summary | Valid Pixels: {len(valid_classes):,} | Mean Confidence: {mean_conf:.3f}',\n","                fontsize=12, y=0.98\n","            )\n","\n","        plt.tight_layout()\n","        plt.savefig(f\"{OUTPUT_DIR}/{tile_name}_classification_result.png\", dpi=200, bbox_inches='tight')\n","        plt.close()\n","\n","        print(f\"  ✓ Saved all outputs\")\n","\n","        # Clean up\n","        del class_map, confidence_map\n","        gc.collect()\n","\n","    except Exception as e:\n","        print(f\"  ✗ Error: {e}\")\n","        import traceback\n","        traceback.print_exc()\n","        gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aDt-ONDn8yzY"},"outputs":[],"source":["# =============================\n","# PROCESS ALL TILES\n","# =============================\n","\n","print(\"\\n\" + \"=\"*70)\n","print(\"PROCESSING TILES FOR PLANTING METHOD\")\n","print(\"=\"*70)\n","\n","results = []\n","\n","for idx, tile_data in enumerate(tile_info):\n","    tile_base = tile_data['base']\n","    bounds = tile_data['bounds']\n","    tile_num = tile_data['number']\n","    crs = tile_data['crs']\n","\n","    print(f\"\\n{'='*70}\")\n","    print(f\"TILE {tile_num} ({idx+1}/{len(tile_info)})\")\n","    print(f\"Base: {os.path.basename(tile_base)}\")\n","    print(f\"CRS: {crs}\")\n","    print(f\"Bounds: {bounds}\")\n","    print('='*70)\n","\n","    tile_name = f\"tile_{tile_num}\"\n","\n","    try:\n","        # Process tile\n","        class_map, confidence_map, actual_bounds = process_tfrecord_streaming_timeseries(\n","                    tile_base,\n","                    model,\n","                    None,  # scaler\n","                    bounds,\n","                    1,     # expected_bands\n","                    18     # sequence_length\n","        )\n","\n","        if class_map is None:\n","            print(\"  ⚠️ Failed to process\")\n","            continue\n","\n","        # Actual bounds\n","        if actual_bounds:\n","            bounds = actual_bounds\n","\n","        # Statistics\n","        valid_class = class_map[~np.isnan(class_map)]\n","        n_valid = len(valid_class)\n","\n","        # Save outputs\n","        print(f\"\\n  Saving outputs...\")\n","        save_geotiff_aligned(\n","            class_map,\n","            f\"{OUTPUT_DIR}/{tile_name}_class.tif\",\n","            bounds,\n","            crs\n","        )\n","        save_geotiff_aligned(\n","            confidence_map,\n","            f\"{OUTPUT_DIR}/{tile_name}_confidence.tif\",\n","            bounds,\n","            crs\n","        )\n","\n","        print(f\"  ✓ Saved all outputs\")\n","\n","        # Clean up\n","        del class_map, confidence_map\n","        gc.collect()\n","\n","    except Exception as e:\n","        print(f\"  ✗ Error: {e}\")\n","        import traceback\n","        traceback.print_exc()\n","        gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EmC9s_WQ7q-1"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"machine_shape":"hm","mount_file_id":"1pKtYq4Rer6mMr6IotvUBAf87QMcOfRCX","authorship_tag":"ABX9TyMz8EU/mlQ6Kr8cZBt11pYX"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}