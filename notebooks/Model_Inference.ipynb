{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HgnKENK_2VaD",
        "outputId": "4def1baa-105a-4888-859f-fe05c1a88f39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: rasterio in /usr/local/lib/python3.12/dist-packages (1.4.3)\n",
            "Collecting pytorch_tabular\n",
            "  Downloading pytorch_tabular-1.1.1-py2.py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: affine in /usr/local/lib/python3.12/dist-packages (from rasterio) (2.4.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.12/dist-packages (from rasterio) (25.4.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from rasterio) (2025.11.12)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.12/dist-packages (from rasterio) (8.3.1)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.12/dist-packages (from rasterio) (0.7.2)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.12/dist-packages (from rasterio) (2.0.2)\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.12/dist-packages (from rasterio) (1.1.1.2)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from rasterio) (3.2.5)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from pytorch_tabular) (2.9.0+cu126)\n",
            "Collecting numpy>=1.24 (from rasterio)\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.12/dist-packages (from pytorch_tabular) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from pytorch_tabular) (1.6.1)\n",
            "Collecting pytorch-lightning<2.5.0,>=2.0.0 (from pytorch_tabular)\n",
            "  Downloading pytorch_lightning-2.4.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: omegaconf>=2.3.0 in /usr/local/lib/python3.12/dist-packages (from pytorch_tabular) (2.3.0)\n",
            "Collecting torchmetrics<1.6.0,>=0.10.0 (from pytorch_tabular)\n",
            "  Downloading torchmetrics-1.5.2-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: tensorboard!=2.5.0,>2.2.0 in /usr/local/lib/python3.12/dist-packages (from pytorch_tabular) (2.19.0)\n",
            "Collecting protobuf<5.29.0,>=3.20.0 (from pytorch_tabular)\n",
            "  Downloading protobuf-5.28.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
            "Collecting pytorch-tabnet==4.1 (from pytorch_tabular)\n",
            "  Downloading pytorch_tabnet-4.1.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: PyYAML<6.1.0,>=5.4 in /usr/local/lib/python3.12/dist-packages (from pytorch_tabular) (6.0.3)\n",
            "Requirement already satisfied: matplotlib>3.1 in /usr/local/lib/python3.12/dist-packages (from pytorch_tabular) (3.10.0)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.12/dist-packages (from pytorch_tabular) (7.7.1)\n",
            "Collecting einops<0.8.0,>=0.6.0 (from pytorch_tabular)\n",
            "  Downloading einops-0.7.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: rich>=11.0.0 in /usr/local/lib/python3.12/dist-packages (from pytorch_tabular) (13.9.4)\n",
            "Requirement already satisfied: scipy>1.4 in /usr/local/lib/python3.12/dist-packages (from pytorch-tabnet==4.1->pytorch_tabular) (1.16.3)\n",
            "Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.12/dist-packages (from pytorch-tabnet==4.1->pytorch_tabular) (4.67.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>3.1->pytorch_tabular) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>3.1->pytorch_tabular) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>3.1->pytorch_tabular) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>3.1->pytorch_tabular) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>3.1->pytorch_tabular) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>3.1->pytorch_tabular) (11.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>3.1->pytorch_tabular) (2.9.0.post0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.12/dist-packages (from omegaconf>=2.3.0->pytorch_tabular) (4.9.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.1.5->pytorch_tabular) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.1.5->pytorch_tabular) (2025.2)\n",
            "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning<2.5.0,>=2.0.0->pytorch_tabular) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from pytorch-lightning<2.5.0,>=2.0.0->pytorch_tabular) (4.15.0)\n",
            "Collecting lightning-utilities>=0.10.0 (from pytorch-lightning<2.5.0,>=2.0.0->pytorch_tabular)\n",
            "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=11.0.0->pytorch_tabular) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=11.0.0->pytorch_tabular) (2.19.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.3.0->pytorch_tabular) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.3.0->pytorch_tabular) (3.6.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard!=2.5.0,>2.2.0->pytorch_tabular) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard!=2.5.0,>2.2.0->pytorch_tabular) (1.76.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard!=2.5.0,>2.2.0->pytorch_tabular) (3.10)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard!=2.5.0,>2.2.0->pytorch_tabular) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.12/dist-packages (from tensorboard!=2.5.0,>2.2.0->pytorch_tabular) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard!=2.5.0,>2.2.0->pytorch_tabular) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard!=2.5.0,>2.2.0->pytorch_tabular) (3.1.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->pytorch_tabular) (3.20.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->pytorch_tabular) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->pytorch_tabular) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->pytorch_tabular) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->pytorch_tabular) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->pytorch_tabular) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->pytorch_tabular) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->pytorch_tabular) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->pytorch_tabular) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->pytorch_tabular) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->pytorch_tabular) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->pytorch_tabular) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->pytorch_tabular) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->pytorch_tabular) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->pytorch_tabular) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->pytorch_tabular) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->pytorch_tabular) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->pytorch_tabular) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->pytorch_tabular) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->pytorch_tabular) (3.5.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.12/dist-packages (from ipywidgets->pytorch_tabular) (6.17.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets->pytorch_tabular) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.12/dist-packages (from ipywidgets->pytorch_tabular) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets->pytorch_tabular) (3.6.10)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets->pytorch_tabular) (7.34.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets->pytorch_tabular) (3.0.16)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning<2.5.0,>=2.0.0->pytorch_tabular) (3.13.2)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets->pytorch_tabular) (1.8.15)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets->pytorch_tabular) (7.4.9)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets->pytorch_tabular) (0.2.1)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets->pytorch_tabular) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets->pytorch_tabular) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets->pytorch_tabular) (26.2.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets->pytorch_tabular) (6.5.1)\n",
            "Collecting jedi>=0.16 (from ipython>=4.0.0->ipywidgets->pytorch_tabular)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets->pytorch_tabular) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets->pytorch_tabular) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets->pytorch_tabular) (3.0.52)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets->pytorch_tabular) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets->pytorch_tabular) (4.9.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=11.0.0->pytorch_tabular) (0.1.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->pytorch_tabular) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard!=2.5.0,>2.2.0->pytorch_tabular) (3.0.3)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.12/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (6.5.7)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<2.5.0,>=2.0.0->pytorch_tabular) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<2.5.0,>=2.0.0->pytorch_tabular) (1.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<2.5.0,>=2.0.0->pytorch_tabular) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<2.5.0,>=2.0.0->pytorch_tabular) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<2.5.0,>=2.0.0->pytorch_tabular) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<2.5.0,>=2.0.0->pytorch_tabular) (1.22.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets->pytorch_tabular) (0.8.5)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets->pytorch_tabular) (0.4)\n",
            "Requirement already satisfied: jupyter-core>=4.9.2 in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets->pytorch_tabular) (5.9.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (25.1.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (5.10.4)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (7.16.6)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (0.23.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (1.3.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets->pytorch_tabular) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets->pytorch_tabular) (0.2.14)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.12/dist-packages (from jupyter-core>=4.9.2->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets->pytorch_tabular) (4.5.0)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.12/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (0.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (4.13.5)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (6.3.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (3.1.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (1.5.1)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.12/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (2.21.2)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.12/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (4.25.1)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.12/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<2.5.0,>=2.0.0->pytorch_tabular) (3.11)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.12/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (25.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (1.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (0.29.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.12/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (2.14.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (2.0.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (2.8)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (2.23)\n",
            "Requirement already satisfied: anyio>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (4.11.0)\n",
            "Requirement already satisfied: jupyter-events>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (0.12.0)\n",
            "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (0.5.3)\n",
            "Requirement already satisfied: overrides>=5.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (7.7.0)\n",
            "Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (1.9.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (1.3.1)\n",
            "Requirement already satisfied: python-json-logger>=2.0.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (4.0.0)\n",
            "Requirement already satisfied: rfc3339-validator in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (0.1.4)\n",
            "Requirement already satisfied: rfc3986-validator>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (0.1.1)\n",
            "Requirement already satisfied: fqdn in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (1.5.1)\n",
            "Requirement already satisfied: isoduration in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (20.11.0)\n",
            "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (3.0.0)\n",
            "Requirement already satisfied: rfc3987-syntax>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (1.1.0)\n",
            "Requirement already satisfied: uri-template in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (1.3.0)\n",
            "Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (25.10.0)\n",
            "Requirement already satisfied: lark>=1.2.2 in /usr/local/lib/python3.12/dist-packages (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (1.3.1)\n",
            "Requirement already satisfied: arrow>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch_tabular) (1.4.0)\n",
            "Downloading pytorch_tabular-1.1.1-py2.py3-none-any.whl (163 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.8/163.8 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_tabnet-4.1.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.5/44.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m94.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-5.28.3-cp38-abi3-manylinux2014_x86_64.whl (316 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.6/316.6 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_lightning-2.4.0-py3-none-any.whl (815 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.2/815.2 kB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.5.2-py3-none-any.whl (891 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m891.4/891.4 kB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: protobuf, numpy, lightning-utilities, jedi, einops, torchmetrics, pytorch-tabnet, pytorch-lightning, pytorch_tabular\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.5\n",
            "    Uninstalling protobuf-5.29.5:\n",
            "      Successfully uninstalled protobuf-5.29.5\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: einops\n",
            "    Found existing installation: einops 0.8.1\n",
            "    Uninstalling einops-0.8.1:\n",
            "      Successfully uninstalled einops-0.8.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "ydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 5.28.3 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed einops-0.7.0 jedi-0.19.2 lightning-utilities-0.15.2 numpy-1.26.4 protobuf-5.28.3 pytorch-lightning-2.4.0 pytorch-tabnet-4.1.0 pytorch_tabular-1.1.1 torchmetrics-1.5.2\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "b9963923c44346d6ac47ff55353aa24c",
              "pip_warning": {
                "packages": [
                  "google",
                  "numpy"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install rasterio pytorch_tabular"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8eU1-9B02emm"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import gc\n",
        "import json\n",
        "import glob\n",
        "import joblib\n",
        "import pickle\n",
        "import rasterio\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tqdm import tqdm\n",
        "from rasterio.transform import from_bounds\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Install pyproj if needed for coordinate transformation\n",
        "try:\n",
        "    from pyproj import Transformer\n",
        "except:\n",
        "    print(\"Installing pyproj...\")\n",
        "    import subprocess\n",
        "    subprocess.check_call(['pip', 'install', 'pyproj'])\n",
        "    from pyproj import Transformer\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from pytorch_tabular import TabularModel\n",
        "from pytorch_tabular.models import FTTransformerConfig\n",
        "from pytorch_tabular.config import DataConfig, OptimizerConfig, TrainerConfig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLuZjFDR2p0P",
        "outputId": "858e9448-fd23-4d09-d6b4-eb17c1ab4586"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "# Check GPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mHK2oozq3THF"
      },
      "outputs": [],
      "source": [
        "# VARIABLES\n",
        "MODEL_PATH = '/content/drive/MyDrive/AGRI/Planting_Method/model/cnn-lstm/CNN-LSTM_dry_model.pth'\n",
        "TFRECORD_DIR = '/content/drive/MyDrive/AGRI/Planting_Method/tfrecord'\n",
        "OUTPUT_DIR = '/content/drive/MyDrive/AGRI/Planting_Method/results'\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "PATCH_SIZE = 256\n",
        "BATCH_SIZE = 512\n",
        "SEQUENCE_LENGTH = 18  # Number of timesteps\n",
        "EXPECTED_BANDS = 1    # Single band per timestep: VH polarization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sNt9jp87AZ0-"
      },
      "outputs": [],
      "source": [
        "class SimplifiedCNNLSTM(nn.Module):\n",
        "    \"\"\"\n",
        "    Simplified CNN-LSTM architecture for better stability and convergence.\n",
        "    Good for imbalanced SAR time-series data.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim, hidden_dim=128, num_layers=2, num_classes=2, dropout_rate=0.3):\n",
        "        super().__init__()\n",
        "\n",
        "        # Simpler CNN with fewer parameters\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv1d(input_dim, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_rate),\n",
        "\n",
        "            nn.Conv1d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_rate)\n",
        "        )\n",
        "\n",
        "        # Bidirectional LSTM\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=128,\n",
        "            hidden_size=hidden_dim,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,\n",
        "            bidirectional=True,\n",
        "            dropout=dropout_rate if num_layers > 1 else 0\n",
        "        )\n",
        "\n",
        "        # Layer normalization\n",
        "        self.ln = nn.LayerNorm(hidden_dim * 2)\n",
        "\n",
        "        # Simple attention\n",
        "        self.attention = nn.Sequential(\n",
        "            nn.Linear(hidden_dim * 2, 64),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(64, 1)\n",
        "        )\n",
        "\n",
        "        # Classifier\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(hidden_dim, num_classes)\n",
        "        )\n",
        "\n",
        "        # Initialize weights\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv1d):\n",
        "                nn.init.kaiming_normal_(m.weight)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_uniform_(m.weight)\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # CNN\n",
        "        x = x.permute(0, 2, 1)\n",
        "        cnn_out = self.cnn(x)\n",
        "        cnn_out = cnn_out.permute(0, 2, 1)\n",
        "\n",
        "        # LSTM\n",
        "        lstm_out, _ = self.lstm(cnn_out)\n",
        "        lstm_out = self.ln(lstm_out)\n",
        "\n",
        "        # Attention\n",
        "        attn_scores = self.attention(lstm_out)\n",
        "        attn_weights = F.softmax(attn_scores, dim=1)\n",
        "        context = torch.sum(attn_weights * lstm_out, dim=1)\n",
        "\n",
        "        # Classification\n",
        "        return self.classifier(context)\n",
        "\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    \"\"\"Residual CNN block with batch normalization\"\"\"\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, dropout=0.3):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size, padding=kernel_size//2)\n",
        "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
        "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size, padding=kernel_size//2)\n",
        "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        # Skip connection\n",
        "        self.skip = nn.Conv1d(in_channels, out_channels, 1) if in_channels != out_channels else nn.Identity()\n",
        "        self.bn_skip = nn.BatchNorm1d(out_channels) if in_channels != out_channels else nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = self.bn_skip(self.skip(x))\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = F.leaky_relu(out, 0.1)\n",
        "        out = self.dropout(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        out += identity  # Residual connection\n",
        "        out = F.leaky_relu(out, 0.1)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class SEBlock(nn.Module):\n",
        "    \"\"\"Squeeze-and-Excitation block for channel attention\"\"\"\n",
        "    def __init__(self, channels, reduction=16):\n",
        "        super().__init__()\n",
        "        self.squeeze = nn.AdaptiveAvgPool1d(1)\n",
        "        self.excitation = nn.Sequential(\n",
        "            nn.Linear(channels, channels // reduction, bias=False),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(channels // reduction, channels, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch, channels, _ = x.size()\n",
        "        y = self.squeeze(x).view(batch, channels)\n",
        "        y = self.excitation(y).view(batch, channels, 1)\n",
        "        return x * y.expand_as(x)\n",
        "\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    \"\"\"Positional encoding for temporal sequences\"\"\"\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        position = torch.arange(max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-np.log(10000.0) / d_model))\n",
        "        pe = torch.zeros(1, max_len, d_model)\n",
        "        pe[0, :, 0::2] = torch.sin(position * div_term)\n",
        "        pe[0, :, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:, :x.size(1), :]\n",
        "        return self.dropout(x)\n",
        "\n",
        "def load_trained_model(model_path, model, device, load_optimizer=False, load_scheduler=False):\n",
        "    \"\"\"\n",
        "    Load a trained model from checkpoint.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    model_path : str\n",
        "        Path to the saved model checkpoint\n",
        "    model : nn.Module\n",
        "        Model instance to load weights into\n",
        "    device : torch.device\n",
        "        Device to load the model on\n",
        "    load_optimizer : bool\n",
        "        Whether to load optimizer state\n",
        "    load_scheduler : bool\n",
        "        Whether to load scheduler state\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    model : nn.Module\n",
        "        Model with loaded weights\n",
        "    checkpoint : dict\n",
        "        Full checkpoint dictionary (contains history, metrics, etc.)\n",
        "    \"\"\"\n",
        "    checkpoint = torch.load(model_path, map_location=device)\n",
        "\n",
        "    # Handle different checkpoint formats\n",
        "    if 'model_state_dict' in checkpoint:\n",
        "        # New format (from train_model_full)\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        print(f\"✓ Loaded model from epoch {checkpoint.get('epoch', 'unknown')}\")\n",
        "        print(f\"✓ Best validation accuracy: {checkpoint.get('best_accuracy', 'unknown'):.4f}\")\n",
        "    else:\n",
        "        # Old format (direct state_dict)\n",
        "        model.load_state_dict(checkpoint)\n",
        "        print(f\"✓ Loaded model state_dict\")\n",
        "\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    return model, checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVgIdP3gAtb-",
        "outputId": "cf49fb9d-6b5c-4b35-f4df-b869add0b350"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Loaded model from epoch 224\n",
            "✓ Best validation accuracy: 0.7981\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "SimplifiedCNNLSTM(\n",
              "  (cnn): Sequential(\n",
              "    (0): Conv1d(18, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): Dropout(p=0.4, inplace=False)\n",
              "    (4): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "    (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (6): ReLU()\n",
              "    (7): Dropout(p=0.4, inplace=False)\n",
              "  )\n",
              "  (lstm): LSTM(128, 128, num_layers=2, batch_first=True, dropout=0.4, bidirectional=True)\n",
              "  (ln): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "  (attention): Sequential(\n",
              "    (0): Linear(in_features=256, out_features=64, bias=True)\n",
              "    (1): Tanh()\n",
              "    (2): Linear(in_features=64, out_features=1, bias=True)\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=256, out_features=128, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Dropout(p=0.4, inplace=False)\n",
              "    (3): Linear(in_features=128, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# # Use simplified model (more stable)\n",
        "model = SimplifiedCNNLSTM(\n",
        "         input_dim=18,\n",
        "         hidden_dim=128,\n",
        "         num_layers=2,\n",
        "         num_classes=2,\n",
        "         dropout_rate=0.4\n",
        ").to(device)\n",
        "\n",
        "model_new, checkpoint = load_trained_model(\n",
        "         model_path='/content/drive/MyDrive/AGRI/Planting_Method/model/CNN-LSTM_dry_model.pth',\n",
        "         model=model,\n",
        "         device=device\n",
        ")\n",
        "\n",
        "model_new.to(device)\n",
        "model_new.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FnGhUx4U_5lY"
      },
      "outputs": [],
      "source": [
        "# =============================\n",
        "# PROCESS TFRECORD - CLASSIFICATION VERSION\n",
        "# =============================\n",
        "\n",
        "def process_tfrecord_streaming_timeseries(tfrecord_base_pattern, model, scaler, tile_bounds,\n",
        "                                          expected_bands=1, sequence_length=18):\n",
        "    \"\"\"\n",
        "    Process TFRecord for time series classification (Transplanted vs Direct-Seeded).\n",
        "\n",
        "    Args:\n",
        "        tfrecord_base_pattern: Base path pattern for TFRecord files\n",
        "        model: PyTorch CNN-LSTM model\n",
        "        scaler: Fitted scaler for normalization (or None)\n",
        "        tile_bounds: [min_lon, min_lat, max_lon, max_lat]\n",
        "        expected_bands: Number of bands per timestep (1 for VH only)\n",
        "        sequence_length: Number of timesteps in the series (18 for your data)\n",
        "\n",
        "    Returns:\n",
        "        classification_map: Array of shape (H, W) with class predictions (0 or 1)\n",
        "        confidence_map: Array of shape (H, W) with prediction confidence\n",
        "        actual_bounds: Adjusted spatial bounds\n",
        "    \"\"\"\n",
        "    print(f\"\\nStreaming processing: {os.path.basename(tfrecord_base_pattern)}\")\n",
        "\n",
        "    # Find all TFRecord files\n",
        "    tfrecord_files = sorted(glob.glob(f\"{tfrecord_base_pattern}-*.tfrecord.gz\"))\n",
        "\n",
        "    if not tfrecord_files:\n",
        "        print(\"  ⚠️ No TFRecord files found!\")\n",
        "        return None, None, None\n",
        "\n",
        "    print(f\"  Found {len(tfrecord_files)} file(s)\")\n",
        "\n",
        "    # Load mixer.json for grid information\n",
        "    mixer_path = f\"{tfrecord_base_pattern}-mixer.json\"\n",
        "    mixer = None\n",
        "    if os.path.exists(mixer_path):\n",
        "        with open(mixer_path, 'r') as f:\n",
        "            mixer = json.load(f)\n",
        "        print(f\"  ✓ Loaded mixer.json\")\n",
        "\n",
        "    if not mixer or 'patchesPerRow' not in mixer:\n",
        "        print(\"  ⚠️ No valid mixer.json found\")\n",
        "        return None, None, None\n",
        "\n",
        "    # Get grid dimensions\n",
        "    patches_per_row = mixer['patchesPerRow']\n",
        "    total_patches = mixer['totalPatches']\n",
        "    num_rows = int(np.ceil(total_patches / patches_per_row))\n",
        "\n",
        "    print(f\"  Grid: {num_rows} rows × {patches_per_row} cols ({total_patches} patches)\")\n",
        "\n",
        "    # Calculate output dimensions\n",
        "    output_h = num_rows * PATCH_SIZE\n",
        "    output_w = patches_per_row * PATCH_SIZE\n",
        "\n",
        "    print(f\"  Output size: {output_h} × {output_w} pixels\")\n",
        "\n",
        "    # Calculate adjusted bounds\n",
        "    min_lon, min_lat, max_lon, max_lat = tile_bounds\n",
        "\n",
        "    actual_pixel_size_lon = (max_lon - min_lon) / output_w\n",
        "    actual_pixel_size_lat = (max_lat - min_lat) / output_h\n",
        "\n",
        "    actual_max_lon = min_lon + (output_w * actual_pixel_size_lon)\n",
        "    actual_max_lat = min_lat + (output_h * actual_pixel_size_lat)\n",
        "\n",
        "    actual_bounds = [min_lon, min_lat, actual_max_lon, actual_max_lat]\n",
        "\n",
        "    print(f\"  Adjusted bounds: [{actual_bounds[0]:.6f}, {actual_bounds[1]:.6f}, \"\n",
        "          f\"{actual_bounds[2]:.6f}, {actual_bounds[3]:.6f}]\")\n",
        "\n",
        "    # Initialize output arrays - use 255 as nodata for uint8\n",
        "    classification_map = np.full((output_h, output_w), 255, dtype=np.uint8)\n",
        "    confidence_map = np.zeros((output_h, output_w), dtype=np.float32)\n",
        "\n",
        "    # Band names for your S1 VH time series\n",
        "    band_names_ordered = [f\"{t}_VH\" for t in range(sequence_length)]\n",
        "\n",
        "    # Track missing bands\n",
        "    missing_bands_count = 0\n",
        "\n",
        "    # Process patches\n",
        "    patch_idx = 0\n",
        "    total_valid_pixels = 0\n",
        "\n",
        "    for file_idx, tfrecord_file in enumerate(tfrecord_files):\n",
        "        print(f\"  Processing file {file_idx+1}/{len(tfrecord_files)}\")\n",
        "\n",
        "        dataset = tf.data.TFRecordDataset(tfrecord_file, compression_type='GZIP')\n",
        "\n",
        "        for raw_record in dataset:\n",
        "            # Parse TFRecord\n",
        "            example = tf.train.Example()\n",
        "            example.ParseFromString(raw_record.numpy())\n",
        "            features = example.features.feature\n",
        "\n",
        "            # Extract time series data with interpolation for missing bands\n",
        "            patch_timeseries = []\n",
        "            available_bands = {}\n",
        "\n",
        "            # First pass: collect all available bands\n",
        "            for band_name in band_names_ordered:\n",
        "                if band_name in features:\n",
        "                    values = np.array(features[band_name].float_list.value)\n",
        "                    timestep_patch = values.reshape(PATCH_SIZE, PATCH_SIZE, 1)\n",
        "                    available_bands[band_name] = timestep_patch\n",
        "\n",
        "            # If we're missing bands, interpolate\n",
        "            if len(available_bands) < sequence_length:\n",
        "                missing_bands_count += 1\n",
        "\n",
        "                # Second pass: interpolate missing bands\n",
        "                for i, band_name in enumerate(band_names_ordered):\n",
        "                    if band_name in available_bands:\n",
        "                        patch_timeseries.append(available_bands[band_name])\n",
        "                    else:\n",
        "                        # Find nearest neighbors for interpolation\n",
        "                        prev_idx = i - 1\n",
        "                        next_idx = i + 1\n",
        "\n",
        "                        # Search backward for valid band\n",
        "                        while prev_idx >= 0 and band_names_ordered[prev_idx] not in available_bands:\n",
        "                            prev_idx -= 1\n",
        "\n",
        "                        # Search forward for valid band\n",
        "                        while next_idx < sequence_length and band_names_ordered[next_idx] not in available_bands:\n",
        "                            next_idx += 1\n",
        "\n",
        "                        # Interpolate\n",
        "                        if prev_idx >= 0 and next_idx < sequence_length:\n",
        "                            prev_band = available_bands[band_names_ordered[prev_idx]]\n",
        "                            next_band = available_bands[band_names_ordered[next_idx]]\n",
        "                            weight = (i - prev_idx) / (next_idx - prev_idx)\n",
        "                            interpolated = prev_band * (1 - weight) + next_band * weight\n",
        "                            patch_timeseries.append(interpolated)\n",
        "                        elif prev_idx >= 0:\n",
        "                            patch_timeseries.append(available_bands[band_names_ordered[prev_idx]])\n",
        "                        elif next_idx < sequence_length:\n",
        "                            patch_timeseries.append(available_bands[band_names_ordered[next_idx]])\n",
        "                        else:\n",
        "                            patch_timeseries = None\n",
        "                            break\n",
        "            else:\n",
        "                # All bands available\n",
        "                patch_timeseries = [available_bands[bn] for bn in band_names_ordered]\n",
        "\n",
        "            if patch_timeseries is None or len(patch_timeseries) != sequence_length:\n",
        "                patch_idx += 1\n",
        "                continue\n",
        "\n",
        "            # Stack timesteps: (seq_len, PATCH_SIZE, PATCH_SIZE, 1)\n",
        "            patch = np.stack(patch_timeseries, axis=0)\n",
        "\n",
        "            # Calculate patch position in output grid\n",
        "            row_idx = patch_idx // patches_per_row\n",
        "            col_idx = patch_idx % patches_per_row\n",
        "\n",
        "            start_h = row_idx * PATCH_SIZE\n",
        "            start_w = col_idx * PATCH_SIZE\n",
        "\n",
        "            # Reshape to pixels: (seq_len, n_pixels, num_bands)\n",
        "            pixels_per_patch = PATCH_SIZE * PATCH_SIZE\n",
        "            pixels = patch.reshape(sequence_length, pixels_per_patch, expected_bands)\n",
        "\n",
        "            # Transpose to: (n_pixels, seq_len, num_bands)\n",
        "            pixels = np.transpose(pixels, (1, 0, 2))\n",
        "\n",
        "            # Find valid pixels (no NaN or 0 across all timesteps)\n",
        "            valid_mask = ~np.any(np.isnan(pixels) | (pixels == 0), axis=(1, 2))\n",
        "            valid_indices = np.where(valid_mask)[0]\n",
        "            n_valid = len(valid_indices)\n",
        "\n",
        "            if n_valid > 0:\n",
        "                total_valid_pixels += n_valid\n",
        "\n",
        "                # Normalize if scaler is provided\n",
        "                if scaler is not None:\n",
        "                    valid_pixels_flat = pixels[valid_indices].reshape(-1, expected_bands)\n",
        "\n",
        "                    import warnings\n",
        "                    with warnings.catch_warnings():\n",
        "                        warnings.filterwarnings('ignore')\n",
        "                        scaled_flat = scaler.transform(valid_pixels_flat)\n",
        "\n",
        "                    valid_features = scaled_flat.reshape(n_valid, sequence_length, expected_bands)\n",
        "                else:\n",
        "                    valid_features = pixels[valid_indices]\n",
        "\n",
        "                # Initialize prediction arrays\n",
        "                patch_classes = np.full(pixels_per_patch, 255, dtype=np.uint8)  # 255 = nodata\n",
        "                patch_conf = np.zeros(pixels_per_patch, dtype=np.float32)\n",
        "\n",
        "                # Process in batches\n",
        "                for start_idx in range(0, n_valid, BATCH_SIZE):\n",
        "                    end_idx = min(start_idx + BATCH_SIZE, n_valid)\n",
        "                    batch_indices = valid_indices[start_idx:end_idx]\n",
        "\n",
        "                    batch_features = valid_features[start_idx:end_idx]\n",
        "\n",
        "                    # Convert to PyTorch tensor: (batch_size, seq_len, num_bands)\n",
        "                    # batch_tensor = torch.from_numpy(batch_features).float().to(device)\n",
        "\n",
        "                    batch_features_reshaped = batch_features.squeeze(-1)  # Remove last dim: (n_valid, 18, 1) -> (n_valid, 18)\n",
        "                    batch_tensor = torch.from_numpy(batch_features_reshaped).float().to(device)\n",
        "                    # Shape: (batch_size, 18)\n",
        "\n",
        "                    # Add feature dimension for model\n",
        "                    batch_tensor = batch_tensor.unsqueeze(1)  # (batch_size, 18) -> (batch_size, 1, 18)\n",
        "                    # Now shape is (batch_size, num_features=1, seq_len=18)\n",
        "\n",
        "                    # Predict with PyTorch model\n",
        "                    with torch.no_grad():\n",
        "                        outputs = model(batch_tensor)  # (batch_size, num_classes)\n",
        "                        probs = torch.softmax(outputs, dim=1)\n",
        "\n",
        "                        # Get predicted class (0 or 1)\n",
        "                        predicted_classes = torch.argmax(probs, dim=1).cpu().numpy()\n",
        "\n",
        "                        # Confidence: max probability\n",
        "                        confidences = torch.max(probs, dim=1)[0].cpu().numpy()\n",
        "\n",
        "                    patch_classes[batch_indices] = predicted_classes\n",
        "                    patch_conf[batch_indices] = confidences\n",
        "\n",
        "                # Reshape and store results\n",
        "                patch_class_map = patch_classes.reshape(PATCH_SIZE, PATCH_SIZE)\n",
        "                patch_conf_map = patch_conf.reshape(PATCH_SIZE, PATCH_SIZE)\n",
        "\n",
        "                classification_map[start_h:start_h+PATCH_SIZE, start_w:start_w+PATCH_SIZE] = patch_class_map\n",
        "                confidence_map[start_h:start_h+PATCH_SIZE, start_w:start_w+PATCH_SIZE] = patch_conf_map\n",
        "\n",
        "            # Clean up\n",
        "            del patch, pixels\n",
        "\n",
        "            patch_idx += 1\n",
        "\n",
        "            # Progress update\n",
        "            if patch_idx % 50 == 0:\n",
        "                progress = (patch_idx / total_patches) * 100\n",
        "                print(f\"    Progress: {progress:.1f}% ({patch_idx}/{total_patches})\")\n",
        "\n",
        "            # Memory cleanup\n",
        "            if patch_idx % 20 == 0:\n",
        "                gc.collect()\n",
        "                if torch.cuda.is_available():\n",
        "                    torch.cuda.empty_cache()\n",
        "\n",
        "    print(f\"  ✓ Processed all {patch_idx} patches\")\n",
        "\n",
        "    if missing_bands_count > 0:\n",
        "        print(f\"  ⚠️ Interpolated missing bands in {missing_bands_count} patches\")\n",
        "\n",
        "    # Statistics\n",
        "    valid_mask = classification_map != 255\n",
        "    valid_classes = classification_map[valid_mask]\n",
        "\n",
        "    if len(valid_classes) > 0:\n",
        "        # Basic statistics\n",
        "        n_direct = (valid_classes == 0).sum()\n",
        "        n_transplanted = (valid_classes == 1).sum()\n",
        "\n",
        "        # Confidence-based statistics\n",
        "        valid_confidence = confidence_map[valid_mask]\n",
        "        high_conf_mask = valid_confidence >= 0.6  # Filter by confidence threshold\n",
        "\n",
        "        high_conf_classes = valid_classes[high_conf_mask]\n",
        "        n_high_conf = len(high_conf_classes)\n",
        "\n",
        "        if n_high_conf > 0:\n",
        "            n_direct_highconf = (high_conf_classes == 0).sum()\n",
        "            n_transplanted_highconf = (high_conf_classes == 1).sum()\n",
        "        else:\n",
        "            n_direct_highconf = 0\n",
        "            n_transplanted_highconf = 0\n",
        "\n",
        "        print(f\"\\n  Classification Statistics:\")\n",
        "        print(f\"    Total valid pixels: {len(valid_classes):,}\")\n",
        "        print(f\"    \")\n",
        "        print(f\"    All Predictions:\")\n",
        "        print(f\"      Class 0 (Direct-Seeded): {n_direct:,} ({n_direct/len(valid_classes)*100:.1f}%)\")\n",
        "        print(f\"      Class 1 (Transplanted):  {n_transplanted:,} ({n_transplanted/len(valid_classes)*100:.1f}%)\")\n",
        "        print(f\"    \")\n",
        "        print(f\"    High Confidence (≥0.6) Predictions:\")\n",
        "        print(f\"      Total: {n_high_conf:,} ({n_high_conf/len(valid_classes)*100:.1f}%)\")\n",
        "        if n_high_conf > 0:\n",
        "            print(f\"      Class 0 (Direct-Seeded): {n_direct_highconf:,} ({n_direct_highconf/n_high_conf*100:.1f}%)\")\n",
        "            print(f\"      Class 1 (Transplanted):  {n_transplanted_highconf:,} ({n_transplanted_highconf/n_high_conf*100:.1f}%)\")\n",
        "        print(f\"    \")\n",
        "        print(f\"    Confidence Statistics:\")\n",
        "        print(f\"      Mean confidence:  {valid_confidence.mean():.3f}\")\n",
        "        print(f\"      Median confidence: {np.median(valid_confidence):.3f}\")\n",
        "        print(f\"      Min confidence:   {valid_confidence.min():.3f}\")\n",
        "        print(f\"      Max confidence:   {valid_confidence.max():.3f}\")\n",
        "\n",
        "    return classification_map, confidence_map, actual_bounds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yeeVhgcO7N9O"
      },
      "outputs": [],
      "source": [
        "# =============================\n",
        "# SAVE GEOTIFF (SAME AS BEFORE)\n",
        "# =============================\n",
        "\n",
        "def save_geotiff_aligned(array, output_path, bounds, crs):\n",
        "    \"\"\"Save array as GeoTIFF with proper georeferencing\"\"\"\n",
        "    h, w = array.shape\n",
        "\n",
        "    min_x, min_y, max_x, max_y = bounds\n",
        "\n",
        "    pixel_width = (max_x - min_x) / w\n",
        "    pixel_height = (max_y - min_y) / h\n",
        "\n",
        "    transform = rasterio.transform.from_bounds(\n",
        "        min_x, min_y, max_x, max_y, w, h\n",
        "    )\n",
        "\n",
        "    print(f\"    Saving: {os.path.basename(output_path)}\")\n",
        "    print(f\"      Size: {w} x {h}\")\n",
        "    print(f\"      Bounds: {bounds}\")\n",
        "\n",
        "\n",
        "\n",
        "    with rasterio.open(\n",
        "        output_path, 'w',\n",
        "        driver='GTiff',\n",
        "        height=h,\n",
        "        width=w,\n",
        "        count=1,\n",
        "        dtype=np.float32,\n",
        "        crs=crs,\n",
        "        transform=transform,\n",
        "        compress='lzw',\n",
        "        nodata=-9999\n",
        "    ) as dst:\n",
        "        dst.write(array, 1)\n",
        "\n",
        "    print(f\"    ✓ Saved\")\n",
        "\n",
        "\n",
        "# =============================\n",
        "# READ TILE MIXER (SAME AS BEFORE)\n",
        "# =============================\n",
        "\n",
        "def read_tile_mixer(tile_base_path):\n",
        "    \"\"\"Read mixer.json and extract georeferencing info\"\"\"\n",
        "    mixer_path = f\"{tile_base_path}-mixer.json\"\n",
        "\n",
        "    if not os.path.exists(mixer_path):\n",
        "        raise FileNotFoundError(f\"mixer.json not found: {mixer_path}\")\n",
        "\n",
        "    with open(mixer_path, 'r') as f:\n",
        "        mixer = json.load(f)\n",
        "\n",
        "    # Extract info\n",
        "    crs = mixer['projection']['crs']\n",
        "    patch_dims = mixer.get('patchDimensions', [256, 256])\n",
        "    patches_per_row = mixer.get('patchesPerRow', 0)\n",
        "    total_patches = mixer.get('totalPatches', 0)\n",
        "\n",
        "    patches_per_col = total_patches // patches_per_row if patches_per_row > 0 else 0\n",
        "\n",
        "    # Extract affine transform\n",
        "    affine_matrix = mixer['projection']['affine']['doubleMatrix']\n",
        "\n",
        "    scale_x = affine_matrix[0]\n",
        "    translate_x = affine_matrix[2]\n",
        "    scale_y = affine_matrix[4]\n",
        "    translate_y = affine_matrix[5]\n",
        "\n",
        "    # Calculate bounds\n",
        "    patch_width_pixels = patch_dims[0]\n",
        "    patch_height_pixels = patch_dims[1]\n",
        "\n",
        "    total_width_pixels = patches_per_row * patch_width_pixels\n",
        "    total_height_pixels = patches_per_col * patch_height_pixels\n",
        "\n",
        "    min_x = translate_x\n",
        "    max_y = translate_y\n",
        "    max_x = min_x + (total_width_pixels * scale_x)\n",
        "    min_y = max_y + (total_height_pixels * scale_y)\n",
        "\n",
        "    bounds = [min_x, min_y, max_x, max_y]\n",
        "\n",
        "    return {\n",
        "        'crs': crs,\n",
        "        'mixer': mixer,\n",
        "        'patch_dims': patch_dims,\n",
        "        'bounds': bounds,\n",
        "        'grid_size': (patches_per_row, patches_per_col),\n",
        "        'pixel_size': (scale_x, abs(scale_y))\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMiMro4k1Vej",
        "outputId": "9e5939c0-a1a8-4f59-d6d5-926c02c96b84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "DISCOVERING TILES\n",
            "======================================================================\n",
            "\n",
            "Found 4 unique tiles\n",
            "\n",
            "  Tile 1: S1_composite_dry2025_tile_001\n",
            "    CRS: EPSG:4326\n",
            "    Grid: 23 x 23\n",
            "    Bounds: [120.58759795199427, 15.193026737256643, 121.11652599128384, 15.721954776546218]\n",
            "\n",
            "  Tile 2: S1_composite_dry2025_tile_002\n",
            "    CRS: EPSG:4326\n",
            "    Grid: 23 x 20\n",
            "    Bounds: [120.58759795199427, 15.67569153941406, 121.11652599128384, 16.135628964883256]\n",
            "\n",
            "  Tile 3: S1_composite_dry2025_tile_003\n",
            "    CRS: EPSG:4326\n",
            "    Grid: 12 x 23\n",
            "    Bounds: [121.08760023913518, 15.19293690572823, 121.3635626944167, 15.721864945017805]\n",
            "\n",
            "  Tile 4: S1_composite_dry2025_tile_004\n",
            "    CRS: EPSG:4326\n",
            "    Grid: 12 x 20\n",
            "    Bounds: [121.08760023913518, 15.675601707885647, 121.3635626944167, 16.135539133354843]\n",
            "\n",
            "✓ Loaded 4 tiles with georeferencing\n"
          ]
        }
      ],
      "source": [
        "# =============================\n",
        "# MAIN PROCESSING\n",
        "# =============================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"DISCOVERING TILES\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Find tiles\n",
        "all_files = glob.glob(f\"{TFRECORD_DIR}/*.tfrecord.gz\")\n",
        "tile_bases = set()\n",
        "\n",
        "for file in all_files:\n",
        "    basename = os.path.basename(file)\n",
        "    base = basename.rsplit('-', 1)[0]\n",
        "    tile_bases.add(os.path.join(TFRECORD_DIR, base))\n",
        "\n",
        "tile_bases = sorted(tile_bases)\n",
        "print(f\"\\nFound {len(tile_bases)} unique tiles\")\n",
        "\n",
        "# Read mixer.json for each\n",
        "tile_info = []\n",
        "\n",
        "for tile_base in tile_bases:\n",
        "    basename = os.path.basename(tile_base)\n",
        "\n",
        "    # Extract tile number\n",
        "    import re\n",
        "    match = re.search(r'tile[_-](\\d+)', basename)\n",
        "    tile_num = int(match.group(1)) if match else None\n",
        "\n",
        "    try:\n",
        "        mixer_data = read_tile_mixer(tile_base)\n",
        "\n",
        "        tile_info.append({\n",
        "            'base': tile_base,\n",
        "            'number': tile_num,\n",
        "            'bounds': mixer_data['bounds'],\n",
        "            'crs': mixer_data['crs'],\n",
        "            'mixer': mixer_data['mixer'],\n",
        "            'grid_size': mixer_data['grid_size'],\n",
        "            'pixel_size': mixer_data['pixel_size']\n",
        "        })\n",
        "\n",
        "        print(f\"\\n  Tile {tile_num}: {basename}\")\n",
        "        print(f\"    CRS: {mixer_data['crs']}\")\n",
        "        print(f\"    Grid: {mixer_data['grid_size'][0]} x {mixer_data['grid_size'][1]}\")\n",
        "        print(f\"    Bounds: {mixer_data['bounds']}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n  ⚠ Error: {e}\")\n",
        "        continue\n",
        "\n",
        "print(f\"\\n✓ Loaded {len(tile_info)} tiles with georeferencing\")\n",
        "\n",
        "if len(tile_info) == 0:\n",
        "    raise ValueError(\"No valid tiles found!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GT1weN3Z8t0G",
        "outputId": "b09df5b4-8775-4a1b-d47e-dcb4cc652881"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "PROCESSING TILES FOR CLASSIFICATION\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "TILE 1 (1/4)\n",
            "Base: S1_composite_dry2025_tile_001\n",
            "CRS: EPSG:4326\n",
            "Bounds: [120.58759795199427, 15.193026737256643, 121.11652599128384, 15.721954776546218]\n",
            "======================================================================\n",
            "\n",
            "Streaming processing: S1_composite_dry2025_tile_001\n",
            "  Found 25 file(s)\n",
            "  ✓ Loaded mixer.json\n",
            "  Grid: 23 rows × 23 cols (529 patches)\n",
            "  Output size: 5888 × 5888 pixels\n",
            "  Adjusted bounds: [120.587598, 15.193027, 121.116526, 15.721955]\n",
            "  Processing file 1/25\n",
            "  Processing file 2/25\n",
            "  Processing file 3/25\n",
            "    Progress: 9.5% (50/529)\n",
            "  Processing file 4/25\n",
            "  Processing file 5/25\n",
            "    Progress: 18.9% (100/529)\n",
            "  Processing file 6/25\n",
            "  Processing file 7/25\n",
            "    Progress: 28.4% (150/529)\n",
            "  Processing file 8/25\n",
            "  Processing file 9/25\n",
            "  Processing file 10/25\n",
            "    Progress: 37.8% (200/529)\n",
            "  Processing file 11/25\n",
            "  Processing file 12/25\n",
            "    Progress: 47.3% (250/529)\n",
            "  Processing file 13/25\n",
            "  Processing file 14/25\n",
            "    Progress: 56.7% (300/529)\n",
            "  Processing file 15/25\n",
            "  Processing file 16/25\n",
            "    Progress: 66.2% (350/529)\n",
            "  Processing file 17/25\n",
            "  Processing file 18/25\n",
            "  Processing file 19/25\n",
            "    Progress: 75.6% (400/529)\n",
            "  Processing file 20/25\n",
            "  Processing file 21/25\n",
            "    Progress: 85.1% (450/529)\n",
            "  Processing file 22/25\n",
            "  Processing file 23/25\n",
            "    Progress: 94.5% (500/529)\n",
            "  Processing file 24/25\n",
            "  Processing file 25/25\n",
            "  ✓ Processed all 529 patches\n",
            "\n",
            "  Classification Statistics:\n",
            "    Total valid pixels: 20,147,494\n",
            "    \n",
            "    All Predictions:\n",
            "      Class 0 (Direct-Seeded): 4,611,621 (22.9%)\n",
            "      Class 1 (Transplanted):  15,535,873 (77.1%)\n",
            "    \n",
            "    High Confidence (≥0.6) Predictions:\n",
            "      Total: 16,708,735 (82.9%)\n",
            "      Class 0 (Direct-Seeded): 3,053,453 (18.3%)\n",
            "      Class 1 (Transplanted):  13,655,282 (81.7%)\n",
            "    \n",
            "    Confidence Statistics:\n",
            "      Mean confidence:  0.737\n",
            "      Median confidence: 0.763\n",
            "      Min confidence:   0.500\n",
            "      Max confidence:   0.950\n",
            "\n",
            "  Tile Statistics:\n",
            "    Valid pixels:        20,147,494\n",
            "    Direct-Seeded (0):   4,611,621 (22.9%)\n",
            "    Transplanted (1):    15,535,873 (77.1%)\n",
            "    Mean confidence:     0.737\n",
            "\n",
            "  Saving outputs...\n",
            "    Saving: tile_001_classification.tif\n",
            "      Size: 5888 x 5888\n",
            "      Bounds: [120.58759795199427, 15.193026737256643, 121.11652599128384, 15.721954776546218]\n",
            "  ✗ Error: Given nodata value, nan, is beyond the valid range of its data type, uint8.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-799641944.py\", line 68, in <cell line: 0>\n",
            "    save_geotiff_aligned(\n",
            "  File \"/tmp/ipython-input-3635084374.py\", line 22, in save_geotiff_aligned\n",
            "    with rasterio.open(\n",
            "         ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/rasterio/env.py\", line 463, in wrapper\n",
            "    return f(*args, **kwds)\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/rasterio/__init__.py\", line 366, in open\n",
            "    dataset = writer(\n",
            "              ^^^^^^^\n",
            "  File \"rasterio/_io.pyx\", line 1553, in rasterio._io.DatasetWriterBase.__init__\n",
            "ValueError: Given nodata value, nan, is beyond the valid range of its data type, uint8.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "TILE 2 (2/4)\n",
            "Base: S1_composite_dry2025_tile_002\n",
            "CRS: EPSG:4326\n",
            "Bounds: [120.58759795199427, 15.67569153941406, 121.11652599128384, 16.135628964883256]\n",
            "======================================================================\n",
            "\n",
            "Streaming processing: S1_composite_dry2025_tile_002\n",
            "  Found 21 file(s)\n",
            "  ✓ Loaded mixer.json\n",
            "  Grid: 20 rows × 23 cols (460 patches)\n",
            "  Output size: 5120 × 5888 pixels\n",
            "  Adjusted bounds: [120.587598, 15.675692, 121.116526, 16.135629]\n",
            "  Processing file 1/21\n",
            "  Processing file 2/21\n"
          ]
        }
      ],
      "source": [
        "# =============================\n",
        "# MAIN PROCESSING LOOP\n",
        "# =============================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"PROCESSING TILES FOR CLASSIFICATION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "results = []\n",
        "\n",
        "for idx, tile_data in enumerate(tile_info):\n",
        "    tile_base = tile_data['base']\n",
        "    bounds = tile_data['bounds']\n",
        "    tile_num = tile_data['number']\n",
        "    crs = tile_data['crs']\n",
        "\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"TILE {tile_num} ({idx+1}/{len(tile_info)})\")\n",
        "    print(f\"Base: {os.path.basename(tile_base)}\")\n",
        "    print(f\"CRS: {crs}\")\n",
        "    print(f\"Bounds: {bounds}\")\n",
        "    print('='*70)\n",
        "\n",
        "    tile_name = f\"tile_{tile_num:03d}\"\n",
        "\n",
        "    try:\n",
        "        # Process tile\n",
        "        class_map, confidence_map, actual_bounds = process_tfrecord_streaming_timeseries(\n",
        "            tile_base, model_new, None, bounds, EXPECTED_BANDS, SEQUENCE_LENGTH\n",
        "        )\n",
        "\n",
        "        if class_map is None:\n",
        "            print(\"  ⚠️ Failed to process\")\n",
        "            continue\n",
        "\n",
        "        # Use actual bounds\n",
        "        if actual_bounds:\n",
        "            bounds = actual_bounds\n",
        "\n",
        "        # Statistics\n",
        "        valid_mask = class_map != 255\n",
        "        valid_classes = class_map[valid_mask]\n",
        "\n",
        "        if len(valid_classes) > 0:\n",
        "            n_direct = (valid_classes == 0).sum()\n",
        "            n_transplanted = (valid_classes == 1).sum()\n",
        "            pct_direct = (n_direct / len(valid_classes)) * 100\n",
        "            pct_transplanted = (n_transplanted / len(valid_classes)) * 100\n",
        "            mean_conf = confidence_map[valid_mask].mean()\n",
        "\n",
        "            print(f\"\\n  Tile Statistics:\")\n",
        "            print(f\"    Valid pixels:        {len(valid_classes):,}\")\n",
        "            print(f\"    Direct-Seeded (0):   {n_direct:,} ({pct_direct:.1f}%)\")\n",
        "            print(f\"    Transplanted (1):    {n_transplanted:,} ({pct_transplanted:.1f}%)\")\n",
        "            print(f\"    Mean confidence:     {mean_conf:.3f}\")\n",
        "\n",
        "            results.append({\n",
        "                'tile': tile_num,\n",
        "                'valid_pixels': len(valid_classes),\n",
        "                'direct_seeded_count': n_direct,\n",
        "                'transplanted_count': n_transplanted,\n",
        "                'direct_seeded_pct': pct_direct,\n",
        "                'transplanted_pct': pct_transplanted,\n",
        "                'mean_confidence': mean_conf\n",
        "            })\n",
        "\n",
        "        # Save outputs\n",
        "        print(f\"\\n  Saving outputs...\")\n",
        "        save_geotiff_aligned(\n",
        "            class_map,\n",
        "            f\"{OUTPUT_DIR}/{tile_name}_classification.tif\",\n",
        "            bounds,\n",
        "            crs\n",
        "        )\n",
        "        save_geotiff_aligned(\n",
        "            confidence_map,\n",
        "            f\"{OUTPUT_DIR}/{tile_name}_confidence.tif\",\n",
        "            bounds,\n",
        "            crs\n",
        "        )\n",
        "\n",
        "        # Create visualization\n",
        "        print(f\"  Creating visualization...\")\n",
        "\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(16, 7))\n",
        "\n",
        "        # Classification map with custom colors\n",
        "        class_vis = np.ma.masked_where(class_map == 255, class_map)\n",
        "\n",
        "        from matplotlib.colors import ListedColormap\n",
        "        colors = ['#2ecc71', '#e67e22']  # Green for Direct-Seeded, Orange for Transplanted\n",
        "        cmap_class = ListedColormap(colors)\n",
        "\n",
        "        im1 = axes[0].imshow(class_vis, cmap=cmap_class, vmin=0, vmax=1, interpolation='nearest')\n",
        "        axes[0].set_title(f'Rice Planting Method Classification (Tile {tile_num})', fontsize=14, fontweight='bold')\n",
        "        axes[0].axis('off')\n",
        "\n",
        "        # Custom legend\n",
        "        from matplotlib.patches import Patch\n",
        "        legend_elements = [\n",
        "            Patch(facecolor='#2ecc71', label=f'Direct-Seeded ({n_direct:,} pixels, {pct_direct:.1f}%)'),\n",
        "            Patch(facecolor='#e67e22', label=f'Transplanted ({n_transplanted:,} pixels, {pct_transplanted:.1f}%)'),\n",
        "            Patch(facecolor='white', edgecolor='black', label=f'No Data')\n",
        "        ]\n",
        "        axes[0].legend(handles=legend_elements, loc='upper right', fontsize=10)\n",
        "\n",
        "        # Confidence map\n",
        "        conf_vis = np.ma.masked_where(class_map == 255, confidence_map)\n",
        "        im2 = axes[1].imshow(conf_vis, cmap='RdYlGn', vmin=0, vmax=1)\n",
        "        axes[1].set_title('Prediction Confidence', fontsize=14, fontweight='bold')\n",
        "        axes[1].axis('off')\n",
        "        cbar2 = plt.colorbar(im2, ax=axes[1], fraction=0.046)\n",
        "        cbar2.set_label('Confidence', rotation=270, labelpad=20, fontsize=11)\n",
        "\n",
        "        if len(valid_classes) > 0:\n",
        "            plt.suptitle(\n",
        "                f'Classification Summary | Valid Pixels: {len(valid_classes):,} | Mean Confidence: {mean_conf:.3f}',\n",
        "                fontsize=12, y=0.98\n",
        "            )\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f\"{OUTPUT_DIR}/{tile_name}_classification_result.png\", dpi=200, bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "        print(f\"  ✓ Saved all outputs\")\n",
        "\n",
        "        # Clean up\n",
        "        del class_map, confidence_map\n",
        "        gc.collect()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"  ✗ Error: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aDt-ONDn8yzY"
      },
      "outputs": [],
      "source": [
        "# =============================\n",
        "# PROCESS ALL TILES\n",
        "# =============================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"PROCESSING TILES FOR BATHYMETRY\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "results = []\n",
        "\n",
        "for idx, tile_data in enumerate(tile_info):\n",
        "    tile_base = tile_data['base']\n",
        "    bounds = tile_data['bounds']\n",
        "    tile_num = tile_data['number']\n",
        "    crs = tile_data['crs']\n",
        "\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"TILE {tile_num} ({idx+1}/{len(tile_info)})\")\n",
        "    print(f\"Base: {os.path.basename(tile_base)}\")\n",
        "    print(f\"CRS: {crs}\")\n",
        "    print(f\"Bounds: {bounds}\")\n",
        "    print('='*70)\n",
        "\n",
        "    tile_name = f\"tile_{tile_num}\"\n",
        "\n",
        "    try:\n",
        "        # Process tile\n",
        "        # In your notebook, replace the old process function call with:\n",
        "        class_map, confidence_map, actual_bounds = process_tfrecord_streaming_timeseries(\n",
        "                    tile_base,\n",
        "                    model,\n",
        "                    None,  # scaler - set to your scaler if you used normalization during training\n",
        "                    bounds,\n",
        "                    1,     # expected_bands\n",
        "                    18     # sequence_length\n",
        "        )\n",
        "\n",
        "        if class_map is None:\n",
        "            print(\"  ⚠️ Failed to process\")\n",
        "            continue\n",
        "\n",
        "        # Use actual bounds\n",
        "        if actual_bounds:\n",
        "            bounds = actual_bounds\n",
        "\n",
        "        # Statistics\n",
        "        valid_class = class_map[~np.isnan(class_map)]\n",
        "        n_valid = len(valid_class)\n",
        "\n",
        "        # Save outputs\n",
        "        print(f\"\\n  Saving outputs...\")\n",
        "        save_geotiff_aligned(\n",
        "            class_map,\n",
        "            f\"{OUTPUT_DIR}/{tile_name}_class.tif\",\n",
        "            bounds,\n",
        "            crs\n",
        "        )\n",
        "        save_geotiff_aligned(\n",
        "            confidence_map,\n",
        "            f\"{OUTPUT_DIR}/{tile_name}_confidence.tif\",\n",
        "            bounds,\n",
        "            crs\n",
        "        )\n",
        "\n",
        "        print(f\"  ✓ Saved all outputs\")\n",
        "\n",
        "        # Clean up\n",
        "        del class_map, confidence_map\n",
        "        gc.collect()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"  ✗ Error: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EmC9s_WQ7q-1"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}